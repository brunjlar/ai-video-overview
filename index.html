<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Video-to-Transcript Summarizer</title>
    <script src="https://cdn.tailwindcss.com?plugins=typography"></script>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">
    <style>
        body {
            font-family: 'Inter', sans-serif;
        }
        .loader {
            border-top-color: #3498db;
            -webkit-animation: spin 1s linear infinite;
            animation: spin 1s linear infinite;
        }
        @keyframes spin {
            0% { transform: rotate(0deg); }
            100% { transform: rotate(360deg); }
        }
        #confirmationModal, #aboutModal {
            transition: opacity 0.3s ease;
        }
        .prose img {
            border-radius: 0.5rem;
            box-shadow: 0 4px 6px -1px rgb(0 0 0 / 0.1), 0 2px 4px -2px rgb(0 0 0 / 0.1);
            margin-left: auto;
            margin-right: auto;
            display: block;
        }
        .prose em {
            color: #6b7280;
            display: block;
            text-align: center;
            font-style: italic;
        }
    </style>
</head>
<body class="bg-gray-50 text-gray-800">

    <div class="container mx-auto max-w-4xl px-4 py-8">
        <header class="text-center mb-8">
            <h1 class="text-4xl font-bold text-gray-900">Video-to-Transcript Summarizer</h1>
            <p class="text-lg text-gray-600 mt-2">Get transcripts with visual context from your videos.</p>
        </header>

        <main>
            <div class="bg-white p-6 rounded-xl shadow-md mb-6">
                <h2 class="text-2xl font-semibold mb-4 text-gray-800">Step 1: Your Gemini API Key</h2>
                <p class="text-gray-600 mb-4">Your API key is stored securely in your browser's local storage.</p>
                <form id="apiKeyForm" onsubmit="return false;">
                    <div class="flex items-center space-x-2">
                        <input type="password" id="apiKey" placeholder="Enter your Gemini API Key" class="flex-grow p-3 border border-gray-300 rounded-lg focus:ring-2 focus:ring-blue-500 focus:outline-none transition">
                        <button id="saveApiKey" type="submit" class="bg-blue-600 text-white font-semibold py-3 px-6 rounded-lg hover:bg-blue-700 transition">Save Key</button>
                    </div>
                </form>
                 <p id="apiKeyStatus" class="text-sm mt-2 text-green-600"></p>
            </div>

            <div class="bg-white p-6 rounded-xl shadow-md mb-6">
                <h2 class="text-2xl font-semibold mb-4 text-gray-800">Step 2: Upload a Video</h2>
                 <div class="flex flex-col items-center justify-center bg-gray-50 p-6 rounded-lg border-2 border-dashed border-gray-300">
                     <label for="videoUpload" class="block text-lg font-medium text-gray-700 mb-2">Upload a Video (.mp4)</label>
                    <input type="file" id="videoUpload" accept="video/mp4" class="w-full text-sm text-gray-500
                        file:mr-4 file:py-2 file:px-4
                        file:rounded-full file:border-0
                        file:text-sm file:font-semibold
                        file:bg-blue-50 file:text-blue-700
                        hover:file:bg-blue-100
                        disabled:opacity-50
                    ">
                    <p id="fileName" class="text-sm mt-2 text-gray-500"></p>
                </div>
            </div>

            <div class="text-center mb-8">
                <button id="processBtn" class="bg-green-600 text-white font-bold py-4 px-8 rounded-lg text-lg hover:bg-green-700 transition shadow-lg disabled:bg-gray-400 disabled:cursor-not-allowed" disabled>
                    Process Video
                </button>
            </div>

            <div id="outputSection" class="bg-white p-6 rounded-xl shadow-md hidden">
                 <div class="flex justify-between items-center mb-4">
                    <h2 class="text-2xl font-semibold text-gray-800">Result</h2>
                    <div id="downloadButtons" class="hidden">
                        <button id="downloadMd" class="bg-gray-700 text-white font-semibold py-2 px-4 rounded-lg hover:bg-gray-800 transition text-sm">Download .md</button>
                        <button id="downloadPdf" class="bg-blue-600 text-white font-semibold py-2 px-4 rounded-lg hover:bg-blue-700 transition text-sm ml-2">Download .pdf</button>
                    </div>
                </div>

                <div id="loadingIndicator" class="text-center py-8 hidden">
                    <div class="loader ease-linear rounded-full border-8 border-t-8 border-gray-200 h-24 w-24 mx-auto"></div>
                    <p id="progressText" class="mt-4 text-lg text-gray-600">Processing video...</p>
                    <button id="interruptBtn" class="mt-4 bg-red-600 text-white font-semibold py-2 px-4 rounded-lg hover:bg-red-700 transition">Interrupt</button>
                </div>

                <div id="result" class="prose max-w-none prose-indigo"></div>
                <div id="error" class="text-red-500 mt-4"></div>
            </div>
        </main>
        
        <footer class="text-center mt-12 text-gray-500 text-sm">
            <button id="aboutBtn" class="underline hover:text-blue-600">About this App</button>
            <p class="mt-2">Created by <a href="mailto:brunjlar@gmail.com" class="underline hover:text-blue-600">Lars Br√ºnjes</a> | <a href="https://github.com/brunjlar/ai-video-overview" target="_blank" rel="noopener noreferrer" class="underline hover:text-blue-600">View on GitHub</a></p>
        </footer>
    </div>

    <div id="aboutModal" class="fixed inset-0 bg-gray-900 bg-opacity-75 flex items-center justify-center p-4 hidden z-50">
        <div class="bg-white rounded-xl shadow-2xl p-8 max-w-2xl w-full relative">
            <button id="closeAboutBtn" class="absolute top-4 right-4 text-gray-500 hover:text-gray-800 text-2xl">&times;</button>
            <div class="prose max-w-none">
                <h2>About the Video-to-Transcript Summarizer</h2>
                <p>This application leverages the power of Google's Gemini AI to transform video content into structured, readable, and context-rich documents. It's designed for students, researchers, and anyone who needs to quickly extract and understand the key information from educational videos, lectures, or talks.</p>
                <h3>How It Works</h3>
                <p>The process happens entirely within your browser, ensuring your data and API key remain private. It uses a sophisticated two-pass workflow to generate high-quality results:</p>
                <ol>
                    <li><strong>Pass 1: Document Structuring:</strong> When you upload a video, the app first sends it to the Gemini 1.5 Flash model. The AI is instructed to analyze the entire video and return a single, well-structured Markdown document. This document includes an overall summary, a list of key takeaways, and the full transcript, correctly divided into chapters with individual summaries. It also identifies 10-15 of the most critical visual moments and inserts simple `[screenshot:...]` placeholder tags at the correct positions within the transcript.</li>
                    <li><strong>Pass 2: Contextual Captioning:</strong> The app then extracts the video frames for each placeholder. In a series of parallel requests, it sends each frame *along with the surrounding text from the transcript* back to the AI. This crucial step provides the necessary context for the AI to generate a meaningful, relevant caption for each image.</li>
                    <li><strong>Final Assembly:</strong> Finally, the app assembles the final document by replacing the placeholders in the text from Pass 1 with the high-quality captions and images from Pass 2, using proper Markdown syntax. This complete document is then rendered on the screen for you to read, review, and download.</li>
                </ol>
                <h3>Why this approach?</h3>
                <p>This two-pass, client-side architecture is designed to be both powerful and private. By breaking the complex task into smaller, focused requests, we get a much more reliable and high-quality result than a single, monolithic request could provide. All processing happens on your machine, so your video data is only ever sent directly to the Google AI API via your own key.</p>
            </div>
        </div>
    </div>


    <script src="https://cdnjs.cloudflare.com/ajax/libs/html2pdf.js/0.10.1/html2pdf.bundle.min.js"></script>
    <script type="module">
        import { GoogleGenerativeAI } from "https://esm.run/@google/generative-ai";
        import { marked } from "https://esm.run/marked";

        document.addEventListener('DOMContentLoaded', () => {
            // --- Element Selectors ---
            const apiKeyForm = document.getElementById('apiKeyForm');
            const apiKeyInput = document.getElementById('apiKey');
            const apiKeyStatus = document.getElementById('apiKeyStatus');
            const videoUploadInput = document.getElementById('videoUpload');
            const fileNameDisplay = document.getElementById('fileName');
            const processBtn = document.getElementById('processBtn');
            const outputSection = document.getElementById('outputSection');
            const loadingIndicator = document.getElementById('loadingIndicator');
            const progressText = document.getElementById('progressText');
            const interruptBtn = document.getElementById('interruptBtn');
            const resultDiv = document.getElementById('result');
            const errorDiv = document.getElementById('error');
            const downloadButtons = document.getElementById('downloadButtons');
            const downloadMdBtn = document.getElementById('downloadMd');
            const downloadPdfBtn = document.getElementById('downloadPdf');
            const aboutBtn = document.getElementById('aboutBtn');
            const aboutModal = document.getElementById('aboutModal');
            const closeAboutBtn = document.getElementById('closeAboutBtn');

            // --- State Variables ---
            let hasResult = false;
            let finalMarkdown = '';
            let abortController;

            // --- Initialization ---
            const storedApiKey = localStorage.getItem('geminiApiKey');
            if (storedApiKey) {
                apiKeyInput.value = '********' + storedApiKey.slice(-4);
                apiKeyStatus.textContent = 'API Key loaded from local storage.';
            } else {
                apiKeyStatus.textContent = 'Please enter your Gemini API Key to enable processing.';
            }
            updateProcessButtonState();

            // --- Event Listeners ---
            apiKeyForm.addEventListener('submit', (event) => {
                event.preventDefault();
                const key = apiKeyInput.value.trim();
                if (key) {
                    localStorage.setItem('geminiApiKey', key);
                    apiKeyStatus.textContent = 'API Key saved successfully!';
                    apiKeyInput.value = '********' + key.slice(-4);
                } else {
                    localStorage.removeItem('geminiApiKey');
                    apiKeyStatus.textContent = 'API Key removed. Please enter a key to enable processing.';
                }
                updateProcessButtonState();
            });
            
            apiKeyInput.addEventListener('focus', () => {
                const storedKey = localStorage.getItem('geminiApiKey');
                if (storedKey) apiKeyInput.value = storedKey;
            });
            apiKeyInput.addEventListener('blur', () => {
                const storedKey = localStorage.getItem('geminiApiKey');
                 if (storedKey) apiKeyInput.value = '********' + storedKey.slice(-4);
            });

            videoUploadInput.addEventListener('change', () => {
                if (videoUploadInput.files.length > 0) {
                    fileNameDisplay.textContent = `Selected file: ${videoUploadInput.files[0].name}`;
                }
            });
            
            processBtn.addEventListener('click', () => {
                if (hasResult) {
                    showConfirmationModal();
                } else {
                    startProcessing();
                }
            });

            interruptBtn.addEventListener('click', () => {
                if (abortController) {
                    abortController.abort("User interrupted processing.");
                }
            });

            aboutBtn.addEventListener('click', () => aboutModal.classList.remove('hidden'));
            closeAboutBtn.addEventListener('click', () => aboutModal.classList.add('hidden'));
            aboutModal.addEventListener('click', (e) => {
                if (e.target === aboutModal) {
                    aboutModal.classList.add('hidden');
                }
            });
            
            downloadMdBtn.addEventListener('click', () => {
                const blob = new Blob([finalMarkdown], { type: 'text/markdown' });
                const url = URL.createObjectURL(blob);
                const a = document.createElement('a');
                a.href = url;
                a.download = 'transcript.md';
                document.body.appendChild(a);
                a.click();
                document.body.removeChild(a);
                URL.revokeObjectURL(url);
            });
            
            downloadPdfBtn.addEventListener('click', () => {
                const element = document.getElementById('result');
                const opt = {
                    margin:       0.5,
                    filename:     'transcript.pdf',
                    image:        { type: 'jpeg', quality: 0.98 },
                    html2canvas:  { scale: 2, useCORS: true },
                    jsPDF:        { unit: 'in', format: 'letter', orientation: 'portrait' }
                };
                html2pdf().set(opt).from(element).save();
            });

            // --- Main Processing Logic ---
            async function startProcessing() {
                resetUI();
                const currentApiKey = localStorage.getItem('geminiApiKey');
                const videoFile = videoUploadInput.files[0];

                if (!validateInputs(currentApiKey, videoFile)) return;
                
                abortController = new AbortController();

                try {
                    // PASS 1: Get the structured markdown with placeholders
                    const preliminaryMarkdown = await getStructuredMarkdown(currentApiKey, videoFile);
                    
                    // Extract frames and their context from the markdown
                    const framesWithContext = await extractFramesAndContext(preliminaryMarkdown, videoFile);

                    // PASS 2: Get refined, context-aware captions for each frame in parallel
                    if (framesWithContext.length > 0) {
                        const refinedCaptions = await getRefinedCaptionsInParallel(currentApiKey, framesWithContext);
                        finalMarkdown = assembleFinalMarkdown(preliminaryMarkdown, framesWithContext, refinedCaptions);
                    } else {
                        progressText.textContent = "No key moments identified. Assembling text-only document...";
                        finalMarkdown = preliminaryMarkdown.replace(/\[screenshot:.*?\]/g, ''); // Clean up any stray tags
                    }
                    
                    resultDiv.innerHTML = marked.parse(finalMarkdown);
                    finalizeUI(true);

                } catch (error) {
                    if (error.name === 'AbortError') {
                        handleError('Processing was interrupted by the user.');
                    } else {
                        handleError(error.message);
                    }
                }
            }

            // --- Helper Functions ---

            function resetUI() {
                hasResult = false;
                finalMarkdown = '';
                errorDiv.textContent = '';
                resultDiv.innerHTML = '';
                outputSection.classList.remove('hidden');
                loadingIndicator.classList.remove('hidden');
                downloadButtons.classList.add('hidden');
                processBtn.disabled = true;
                setInputsDisabled(true);
                progressText.textContent = 'Initializing...';
            }

            function validateInputs(apiKey, file) {
                if (!apiKey) {
                    handleError('Please save your Gemini API Key first.');
                    return false;
                }
                if (!file) {
                    handleError('Please upload a video file.');
                    return false;
                }
                return true;
            }

            function finalizeUI(success) {
                loadingIndicator.classList.add('hidden');
                updateProcessButtonState();
                setInputsDisabled(false);
                if (success) {
                    downloadButtons.classList.remove('hidden');
                    hasResult = true; 
                    videoUploadInput.value = '';
                    fileNameDisplay.textContent = '';
                }
            }

            async function fileToGenerativePart(file) {
                const base64EncodedDataPromise = new Promise((resolve) => {
                    const reader = new FileReader();
                    reader.onloadend = () => resolve(reader.result.split(',')[1]);
                    reader.readAsDataURL(file);
                });
                return {
                    inlineData: { data: await base64EncodedDataPromise, mimeType: file.type },
                };
            }

            /**
             * NEW: Wraps a model.generateContent call with a retry mechanism featuring exponential backoff.
             */
            async function generateContentWithRetry(model, prompt, maxRetries = 5) {
                let lastError;
                for (let i = 0; i < maxRetries; i++) {
                    // Check for user interruption before making the API call
                    if (abortController && abortController.signal.aborted) {
                        throw new DOMException("Aborted by user", "AbortError");
                    }
                    try {
                        const result = await model.generateContent(prompt);
                        return result; // Success
                    } catch (error) {
                        lastError = error;
                        // Check if the error indicates a retryable condition (e.g., server overload)
                        if (error.toString().includes('503') || error.toString().includes('overloaded')) {
                            const delay = (2 ** i * 1000) + (Math.random() * 1000); // Exponential backoff with jitter
                            console.warn(`API call failed (attempt ${i + 1}/${maxRetries}). Retrying in ${Math.round(delay)}ms...`);
                            await new Promise(resolve => setTimeout(resolve, delay));
                        } else {
                            // Not a retryable error, so rethrow immediately
                            throw error;
                        }
                    }
                }
                // If all retries fail, throw the last captured error
                throw new Error(`API call failed after ${maxRetries} attempts. Last error: ${lastError}`);
            }


            async function getStructuredMarkdown(apiKey, file) {
                const genAI = new GoogleGenerativeAI(apiKey);
                const model = genAI.getGenerativeModel({ model: "gemini-1.5-flash-latest" });

                progressText.textContent = "Pass 1/2: Analyzing video and generating document structure...";
                const videoPart = await fileToGenerativePart(file);
                
                // FIX: Refined the prompt to be more explicit about tag placement.
                const prompt = `
You are an expert technical writer and video analyst. Your task is to create a single, comprehensive document from the provided video, formatted in Markdown.

Follow this exact structure:

1.  Create a main heading '## Overall Summary' and write a one-paragraph summary of the entire video.
2.  Create a main heading '## Key Takeaways' and write a bulleted list of the 3-5 most important points.
3.  Then, identify the logical chapters in the video. For each chapter, you MUST create the following block:
    - A subheading: '### Chapter: [Chapter Title]'
    - A one-paragraph summary of that chapter.
    - The full, clean transcript for that chapter.
    - CRUCIALLY: As you write the transcript, you MUST insert a placeholder tag on its own line (with an empty line before and after) immediately after the sentence that references a key visual moment.
    - The tag format is: [screenshot:HH:MM:SS]

    For example:
    > This is a sentence in the transcript that refers to a diagram.
    >
    > [screenshot:01:23:45]
    >
    > The transcript then continues with the next sentence.

Select 10-15 of the most critical visual moments.
The response must be PURE MARKDOWN. Do not add any conversational text like "Certainly, here is your markdown."
`;
                // Use the new retry wrapper for the API call
                const result = await generateContentWithRetry(model, [prompt, videoPart]);
                return result.response.text();
            }
            
            async function extractFramesAndContext(markdown, videoFile) {
                const timestampRegex = /\[screenshot:(\d{2}):(\d{2}):(\d{2})\]/g;
                const matches = [...markdown.matchAll(timestampRegex)];
                const frames = [];

                if (matches.length > 0) {
                    progressText.textContent = `Pass 1/2: Found ${matches.length} key moments. Extracting frames...`;
                    for (let i = 0; i < matches.length; i++) {
                        if (abortController.signal.aborted) throw new DOMException("Aborted", "AbortError");
                        const match = matches[i];
                        const [fullMatch, hh, mm, ss] = match;
                        const timeInSeconds = parseInt(hh) * 3600 + parseInt(mm) * 60 + parseInt(ss);
                        
                        const contextChars = 300;
                        const tagIndex = match.index;
                        const startIndex = Math.max(0, tagIndex - contextChars);
                        const endIndex = Math.min(markdown.length, tagIndex + contextChars);
                        const context = markdown.substring(startIndex, endIndex);

                        try {
                            const frameDataUrl = await extractFrameAtTime(videoFile, timeInSeconds);
                            frames.push({
                                tag: fullMatch,
                                dataUrl: frameDataUrl,
                                context: context
                            });
                        } catch (e) {
                            console.error(`Could not extract frame at ${timeInSeconds}s:`, e);
                        }
                    }
                }
                return frames;
            }

            async function getRefinedCaptionsInParallel(apiKey, framesWithContext) {
                progressText.textContent = `Pass 2/2: Refining captions for ${framesWithContext.length} screenshots...`;
                const genAI = new GoogleGenerativeAI(apiKey);
                const model = genAI.getGenerativeModel({ model: "gemini-1.5-flash-latest" });

                const captionPromises = framesWithContext.map(frame => {
                    const prompt = `You are a visual analyst. Based on the provided image and its surrounding text context, write a single, concise, meaningful, one-sentence caption. The caption should describe the visual content and explain its relevance to the topic being discussed. Respond with only the caption text, nothing else.

Context from transcript:
---
${frame.context}
---
`;
                    const imagePart = {
                        inlineData: {
                            mimeType: 'image/jpeg',
                            data: frame.dataUrl.split(',')[1]
                        }
                    };
                    
                    // FIX: Use the new retry wrapper for each caption generation call
                    return generateContentWithRetry(model, [prompt, imagePart])
                        .then(result => result.response.text())
                        .catch(err => {
                            console.error("Caption generation failed for a frame after all retries:", err);
                            return "A key visual from the video."; // Fallback caption
                        });
                });

                return Promise.all(captionPromises);
            }


            function assembleFinalMarkdown(markdown, frames, captions) {
                let tempMarkdown = markdown;
                if (frames.length === captions.length) {
                    for (let i = 0; i < frames.length; i++) {
                        const frame = frames[i];
                        const caption = captions[i].replace(/"/g, '').trim();
                        const imageMarkdown = `\n![${caption}](${frame.dataUrl})\n*${caption}*`;
                        tempMarkdown = tempMarkdown.replace(frame.tag, imageMarkdown);
                    }
                } else {
                     for (const frame of frames) {
                        const imageMarkdown = `\n![Frame without caption](${frame.dataUrl})\n`;
                        tempMarkdown = tempMarkdown.replace(frame.tag, imageMarkdown);
                    }
                }
                return tempMarkdown;
            }

            function extractFrameAtTime(file, timeInSeconds) {
                return new Promise((resolve, reject) => {
                    const video = document.createElement('video');
                    const canvas = document.createElement('canvas');
                    const context = canvas.getContext('2d');
                    
                    video.src = URL.createObjectURL(file);
                    video.muted = true;

                    video.onloadedmetadata = () => {
                        canvas.width = video.videoWidth;
                        canvas.height = video.videoHeight;
                        video.currentTime = timeInSeconds;
                    };

                    video.onseeked = () => {
                        if (video.currentTime >= timeInSeconds) {
                            context.drawImage(video, 0, 0, canvas.width, canvas.height);
                            URL.revokeObjectURL(video.src);
                            resolve(canvas.toDataURL('image/jpeg'));
                        }
                    };

                    video.onerror = (e) => {
                        URL.revokeObjectURL(video.src);
                        reject(new Error('Failed to load or seek video.'));
                    };
                });
            }

            function handleError(message) {
                errorDiv.textContent = `Error: ${message}`;
                finalizeUI(false);
            }

            function updateProcessButtonState() {
                processBtn.disabled = !localStorage.getItem('geminiApiKey');
            }

            function setInputsDisabled(disabled) {
                videoUploadInput.disabled = disabled;
            }

            function showConfirmationModal() {
                confirmationModal.classList.remove('hidden');
            }

            function hideConfirmationModal() {
                confirmationModal.classList.add('hidden');
            }
        });
    </script>
</body>
</html>