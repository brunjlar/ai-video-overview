<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Video-to-Transcript Summarizer</title>
    <script src="https://cdn.tailwindcss.com?plugins=typography"></script>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">
    <style>
        body {
            font-family: 'Inter', sans-serif;
        }

        .loader {
            border-top-color: #3498db;
            -webkit-animation: spin 1s linear infinite;
            animation: spin 1s linear infinite;
        }

        @keyframes spin {
            0% {
                transform: rotate(0deg);
            }

            100% {
                transform: rotate(360deg);
            }
        }

        #confirmationModal,
        #aboutModal {
            transition: opacity 0.3s ease;
        }

        .prose img {
            border-radius: 0.5rem;
            box-shadow: 0 4px 6px -1px rgb(0 0 0 / 0.1), 0 2px 4px -2px rgb(0 0 0 / 0.1);
            margin-left: auto;
            margin-right: auto;
            display: block;
        }

        .prose em {
            color: #6b7280;
            display: block;
            text-align: center;
            font-style: italic;
        }
    </style>
</head>

<body class="bg-gray-50 text-gray-800">

    <div class="container mx-auto max-w-4xl px-4 py-8">
        <header class="text-center mb-8">
            <h1 class="text-4xl font-bold text-gray-900">Video-to-Transcript Summarizer</h1>
            <p class="text-lg text-gray-600 mt-2">Get transcripts with visual context from your videos.</p>
        </header>

        <main>
            <div class="bg-white p-6 rounded-xl shadow-md mb-6">
                <h2 class="text-2xl font-semibold mb-4 text-gray-800">Step 1: Your Gemini API Key</h2>
                <p class="text-gray-600 mb-4">Your API key is stored securely in your browser's local storage.</p>
                <form id="apiKeyForm" onsubmit="return false;">
                    <div class="flex items-center space-x-2">
                        <input type="password" id="apiKey" placeholder="Enter your Gemini API Key"
                            class="flex-grow p-3 border border-gray-300 rounded-lg focus:ring-2 focus:ring-blue-500 focus:outline-none transition">
                        <button id="saveApiKey" type="submit"
                            class="bg-blue-600 text-white font-semibold py-3 px-6 rounded-lg hover:bg-blue-700 transition">Save
                            Key</button>
                    </div>
                </form>
                <p id="apiKeyStatus" class="text-sm mt-2 text-green-600"></p>
            </div>

            <div class="bg-white p-6 rounded-xl shadow-md mb-6">
                <h2 class="text-2xl font-semibold mb-4 text-gray-800">Step 2: Upload a Video</h2>
                <div
                    class="flex flex-col items-center justify-center bg-gray-50 p-6 rounded-lg border-2 border-dashed border-gray-300">
                    <label for="videoUpload" class="block text-lg font-medium text-gray-700 mb-2">Upload a Video
                        (.mp4)</label>
                    <input type="file" id="videoUpload" accept="video/mp4" class="w-full text-sm text-gray-500
                        file:mr-4 file:py-2 file:px-4
                        file:rounded-full file:border-0
                        file:text-sm file:font-semibold
                        file:bg-blue-50 file:text-blue-700
                        hover:file:bg-blue-100
                        disabled:opacity-50
                    ">
                    <p id="fileName" class="text-sm mt-2 text-gray-500"></p>
                </div>
            </div>

            <div class="text-center mb-8">
                <button id="processBtn"
                    class="bg-green-600 text-white font-bold py-4 px-8 rounded-lg text-lg hover:bg-green-700 transition shadow-lg disabled:bg-gray-400 disabled:cursor-not-allowed"
                    disabled>
                    Process Video
                </button>
            </div>

            <div id="outputSection" class="bg-white p-6 rounded-xl shadow-md hidden">
                <div class="flex justify-between items-center mb-4">
                    <h2 class="text-2xl font-semibold text-gray-800">Result</h2>
                    <div id="downloadButtons" class="hidden">
                        <button id="downloadMd"
                            class="bg-gray-700 text-white font-semibold py-2 px-4 rounded-lg hover:bg-gray-800 transition text-sm">Download
                            .md</button>
                        <button id="downloadPdf"
                            class="bg-blue-600 text-white font-semibold py-2 px-4 rounded-lg hover:bg-blue-700 transition text-sm ml-2">Download
                            .pdf</button>
                    </div>
                </div>

                <div id="loadingIndicator" class="text-center py-8 hidden">
                    <div class="loader ease-linear rounded-full border-8 border-t-8 border-gray-200 h-24 w-24 mx-auto">
                    </div>
                    <p id="progressText" class="mt-4 text-lg text-gray-600">Processing video...</p>
                    <button id="interruptBtn"
                        class="mt-4 bg-red-600 text-white font-semibold py-2 px-4 rounded-lg hover:bg-red-700 transition">Interrupt</button>
                </div>

                <div id="result" class="prose max-w-none prose-indigo"></div>
                <div id="error" class="text-red-500 mt-4"></div>
            </div>
        </main>

        <footer class="text-center mt-12 text-gray-500 text-sm">
            <button id="aboutBtn" class="underline hover:text-blue-600">About this App</button>
            <p class="mt-2">Created by <a href="mailto:brunjlar@gmail.com" class="underline hover:text-blue-600">Lars
                    Br√ºnjes</a> | <a href="https://github.com/brunjlar/ai-video-overview" target="_blank"
                    rel="noopener noreferrer" class="underline hover:text-blue-600">View on GitHub</a></p>
        </footer>
    </div>

    <div id="aboutModal"
        class="fixed inset-0 bg-gray-900 bg-opacity-75 flex items-center justify-center p-4 hidden z-50">
        <div class="bg-white rounded-xl shadow-2xl p-8 max-w-2xl w-full relative">
            <button id="closeAboutBtn"
                class="absolute top-4 right-4 text-gray-500 hover:text-gray-800 text-2xl">&times;</button>
            <div class="prose max-w-none">
                <h2>About the Video-to-Transcript Summarizer</h2>
                <p>This application leverages the power of Google's Gemini AI to transform video content into
                    structured, readable, and context-rich documents. It's designed for students, researchers, and
                    anyone who needs to quickly extract and understand the key information from educational videos,
                    lectures, or talks.</p>
                <h3>How It Works</h3>
                <p>The process happens entirely within your browser, ensuring your data and API key remain private. It
                    uses a sophisticated two-pass workflow to generate high-quality results:</p>
                <ol>
                    <li><strong>Pass 1: Document Structuring:</strong> When you upload a video, the app first sends it
                        to the Gemini 1.5 Flash model. The AI is instructed to analyze the entire video and return a
                        single, well-structured Markdown document. This document includes an overall summary, a list of
                        key takeaways, and the full transcript, correctly divided into chapters with individual
                        summaries. It also identifies 10-15 of the most critical visual moments and inserts simple
                        `[screenshot:...]` placeholder tags at the correct positions within the transcript.</li>
                    <li><strong>Pass 2: Contextual Captioning:</strong> The app then extracts the video frames for each
                        placeholder. In a series of parallel requests, it sends each frame *along with the surrounding
                        text from the transcript* back to the AI. This crucial step provides the necessary context for
                        the AI to generate a meaningful, relevant caption for each image.</li>
                    <li><strong>Final Assembly:</strong> Finally, the app assembles the final document by replacing the
                        placeholders in the text from Pass 1 with the high-quality captions and images from Pass 2,
                        using proper Markdown syntax. This complete document is then rendered on the screen for you to
                        read, review, and download.</li>
                </ol>
                <h3>Why this approach?</h3>
                <p>This two-pass, client-side architecture is designed to be both powerful and private. By breaking the
                    complex task into smaller, focused requests, we get a much more reliable and high-quality result
                    than a single, monolithic request could provide. All processing happens on your machine, so your
                    video data is only ever sent directly to the Google AI API via your own key.</p>
            </div>
        </div>
    </div>


    <script src="https://cdnjs.cloudflare.com/ajax/libs/html2pdf.js/0.10.1/html2pdf.bundle.min.js"></script>
    <script type="module">
        import { GoogleGenerativeAI } from "https://esm.run/@google/generative-ai";
        import { marked } from "https://esm.run/marked";

        document.addEventListener('DOMContentLoaded', () => {
            // --- Element Selectors ---
            const apiKeyForm = document.getElementById('apiKeyForm');
            const apiKeyInput = document.getElementById('apiKey');
            const apiKeyStatus = document.getElementById('apiKeyStatus');
            const videoUploadInput = document.getElementById('videoUpload');
            const fileNameDisplay = document.getElementById('fileName');
            const processBtn = document.getElementById('processBtn');
            const outputSection = document.getElementById('outputSection');
            const loadingIndicator = document.getElementById('loadingIndicator');
            const progressText = document.getElementById('progressText');
            const interruptBtn = document.getElementById('interruptBtn');
            const resultDiv = document.getElementById('result');
            const errorDiv = document.getElementById('error');
            const downloadButtons = document.getElementById('downloadButtons');
            const downloadMdBtn = document.getElementById('downloadMd');
            const downloadPdfBtn = document.getElementById('downloadPdf');
            const aboutBtn = document.getElementById('aboutBtn');
            const aboutModal = document.getElementById('aboutModal');
            const closeAboutBtn = document.getElementById('closeAboutBtn');

            // --- State Variables ---
            let hasResult = false;
            let finalMarkdown = '';
            let abortController;

            // --- Initialization ---
            const storedApiKey = localStorage.getItem('geminiApiKey');
            if (storedApiKey) {
                apiKeyInput.value = '********' + storedApiKey.slice(-4);
                apiKeyStatus.textContent = 'API Key loaded from local storage.';
            } else {
                apiKeyStatus.textContent = 'Please enter your Gemini API Key to enable processing.';
            }
            updateProcessButtonState();

            // --- Event Listeners ---
            apiKeyForm.addEventListener('submit', (event) => {
                event.preventDefault();
                const key = apiKeyInput.value.trim();
                if (key) {
                    localStorage.setItem('geminiApiKey', key);
                    apiKeyStatus.textContent = 'API Key saved successfully!';
                    apiKeyInput.value = '********' + key.slice(-4);
                } else {
                    localStorage.removeItem('geminiApiKey');
                    apiKeyStatus.textContent = 'API Key removed. Please enter a key to enable processing.';
                }
                updateProcessButtonState();
            });

            apiKeyInput.addEventListener('focus', () => {
                const storedKey = localStorage.getItem('geminiApiKey');
                if (storedKey) apiKeyInput.value = storedKey;
            });
            apiKeyInput.addEventListener('blur', () => {
                const storedKey = localStorage.getItem('geminiApiKey');
                if (storedKey) apiKeyInput.value = '********' + storedKey.slice(-4);
            });

            videoUploadInput.addEventListener('change', () => {
                if (videoUploadInput.files.length > 0) {
                    fileNameDisplay.textContent = `Selected file: ${videoUploadInput.files[0].name}`;
                }
            });

            processBtn.addEventListener('click', () => {
                if (hasResult) {
                    showConfirmationModal();
                } else {
                    startProcessing();
                }
            });

            interruptBtn.addEventListener('click', () => {
                if (abortController) {
                    abortController.abort("User interrupted processing.");
                }
            });

            aboutBtn.addEventListener('click', () => aboutModal.classList.remove('hidden'));
            closeAboutBtn.addEventListener('click', () => aboutModal.classList.add('hidden'));
            aboutModal.addEventListener('click', (e) => {
                if (e.target === aboutModal) {
                    aboutModal.classList.add('hidden');
                }
            });

            downloadMdBtn.addEventListener('click', () => {
                const blob = new Blob([finalMarkdown], { type: 'text/markdown' });
                const url = URL.createObjectURL(blob);
                const a = document.createElement('a');
                a.href = url;
                a.download = 'transcript.md';
                document.body.appendChild(a);
                a.click();
                document.body.removeChild(a);
                URL.revokeObjectURL(url);
            });

            downloadPdfBtn.addEventListener('click', () => {
                const element = document.getElementById('result');
                const opt = {
                    margin: 0.5,
                    filename: 'transcript.pdf',
                    image: { type: 'jpeg', quality: 0.98 },
                    html2canvas: { scale: 2, useCORS: true },
                    jsPDF: { unit: 'in', format: 'letter', orientation: 'portrait' }
                };
                html2pdf().set(opt).from(element).save();
            });

            // --- Main Processing Logic ---
            async function startProcessing() {
                console.info("===== PROCESSING STARTED =====");
                resetUI();
                const currentApiKey = localStorage.getItem('geminiApiKey');
                const videoFile = videoUploadInput.files[0];

                if (!validateInputs(currentApiKey, videoFile)) {
                    console.error("Input validation failed. Aborting.");
                    return;
                }

                abortController = new AbortController();

                try {
                    // PASS 1: Get the structured markdown with placeholders
                    console.info("--- PASS 1: GETTING STRUCTURED MARKDOWN ---");
                    const preliminaryMarkdown = await getStructuredMarkdown(currentApiKey, videoFile);
                    console.log("Received preliminary markdown from API:", preliminaryMarkdown);

                    // FRAME EXTRACTION
                    console.info("--- FRAME EXTRACTION ---");
                    const { frames, cleanedMarkdown } = await extractFramesAndContext(preliminaryMarkdown, videoFile);
                    console.info(`Found ${frames.length} valid screenshot tags.`)

                    // PASS 2: Get refined, context-aware captions for each frame in parallel
                    if (frames.length > 0) {
                        console.info(`--- PASS 2: GETTING ${frames.length} CAPTIONS ---`);
                        const refinedCaptions = await getRefinedCaptionsInParallel(currentApiKey, frames);
                        finalMarkdown = assembleFinalMarkdown(cleanedMarkdown, frames, refinedCaptions);
                    } else {
                        progressText.textContent = "No key moments identified. Assembling text-only document...";
                        console.info("No valid screenshot tags found. Skipping caption generation.");
                        finalMarkdown = cleanedMarkdown.replace(/\[screenshot:.*?\]/g, ''); // Clean up any stray tags
                    }

                    console.info("--- FINAL ASSEMBLY ---");
                    resultDiv.innerHTML = marked.parse(finalMarkdown);
                    finalizeUI(true);
                    console.info("===== PROCESSING FINISHED SUCCESSFULLY =====");

                } catch (error) {
                    if (error.name === 'AbortError') {
                        handleError('Processing was interrupted by the user.');
                        console.warn("Processing was interrupted by the user.");
                    } else {
                        handleError(error.message);
                        console.error("An unrecoverable error occurred:", error);
                    }
                    console.error("===== PROCESSING FAILED =====");
                }
            }

            // --- Helper Functions ---

            function resetUI() {
                hasResult = false;
                finalMarkdown = '';
                errorDiv.textContent = '';
                resultDiv.innerHTML = '';
                outputSection.classList.remove('hidden');
                loadingIndicator.classList.remove('hidden');
                downloadButtons.classList.add('hidden');
                processBtn.disabled = true;
                setInputsDisabled(true);
                progressText.textContent = 'Initializing...';
            }

            function validateInputs(apiKey, file) {
                if (!apiKey) {
                    handleError('Please save your Gemini API Key first.');
                    return false;
                }
                if (!file) {
                    handleError('Please upload a video file.');
                    return false;
                }
                return true;
            }

            function finalizeUI(success) {
                loadingIndicator.classList.add('hidden');
                updateProcessButtonState();
                setInputsDisabled(false);
                if (success) {
                    downloadButtons.classList.remove('hidden');
                    hasResult = true;
                    videoUploadInput.value = '';
                    fileNameDisplay.textContent = '';
                }
            }

            async function fileToGenerativePart(file) {
                const base64EncodedDataPromise = new Promise((resolve) => {
                    const reader = new FileReader();
                    reader.onloadend = () => resolve(reader.result.split(',')[1]);
                    reader.readAsDataURL(file);
                });
                return {
                    inlineData: { data: await base64EncodedDataPromise, mimeType: file.type },
                };
            }

            async function generateContentWithRetry(model, prompt, maxRetries = 5, requestName = "Generic") {
                let lastError;
                for (let i = 0; i < maxRetries; i++) {
                    if (abortController && abortController.signal.aborted) {
                        throw new DOMException("Aborted by user", "AbortError");
                    }
                    try {
                        console.log(`[API Request: ${requestName}] Attempt ${i + 1}/${maxRetries}...`);
                        const result = await model.generateContent(prompt);
                        console.log(`[API Request: ${requestName}] Success.`);
                        return result;
                    } catch (error) {
                        lastError = error;
                        if (error.toString().includes('503') || error.toString().includes('overloaded')) {
                            const delay = (2 ** i * 1000) + (Math.random() * 1000);
                            console.warn(`[API Request: ${requestName}] Failed (attempt ${i + 1}/${maxRetries}). Retrying in ${Math.round(delay)}ms...`);
                            await new Promise(resolve => setTimeout(resolve, delay));
                        } else {
                            console.error(`[API Request: ${requestName}] Failed with non-retryable error:`, error);
                            throw error;
                        }
                    }
                }
                console.error(`[API Request: ${requestName}] Failed after all ${maxRetries} attempts.`);
                throw new Error(`API call failed after ${maxRetries} attempts. Last error: ${lastError}`);
            }

            async function getStructuredMarkdown(apiKey, file) {
                const genAI = new GoogleGenerativeAI(apiKey);
                const model = genAI.getGenerativeModel({ model: "gemini-2.5-pro" });

                progressText.textContent = "Pass 1/2: Analyzing video and generating Markdown...";

                const videoPart = await fileToGenerativePart(file);

                const systemPrompt = `
You are a professional technical video summarizer. Your job is to turn a video transcript and keyframes into a clean, structured Markdown document suitable for blog posts or course material.

**Format Requirements:**

- Organize the document into chapters with H3 headers: \`### Chapter: [Title]\`
- Each chapter must have:
  - A short **summary** paragraph at the top
  - A full **transcript** of what is said in that chapter, without omitting or summarizing
  - Inline **[screenshot:MM:SS:FF]** tags for each timestamp provided
- Screenshot tags must appear **in the transcript**, on their own line, surrounded by blank lines.
- Markdown must be returned as a code block with \`\`\`markdown at the top and \`\`\` at the end.

**Example:**

### Chapter: Introduction

**Summary:**
Lars introduces the topic of Cardano incentives and outlines the structure of the presentation.

**Transcript:**

Welcome to the talk on Cardano's incentive system.

[screenshot:00:01:23]

This system ensures the network stays decentralized and secure.

[screenshot:00:02:10]

...

Make the output readable, but do not summarize or paraphrase the transcript.

Remember to only pick at most 10-15 key moments from the video; 
Only include the most important screenshots that illustrate the key points discussed in each chapter and
which are needed to understand the transcript.
`;

                const result = await generateContentWithRetry(
                    model,
                    {
                        systemInstruction: {
                            role: "system",
                            parts: [{ text: systemPrompt }]
                        },
                        contents: [
                            { role: "user", parts: [videoPart] }
                        ],
                        generationConfig: {
                            responseMimeType: "text/plain"
                        }
                    },
                    5,
                    "Initial Structure (Pro Model with systemInstruction)"
                );

                const raw = result.response.text();
                const cleaned = raw.includes("#") ? raw.slice(raw.indexOf("#")) : raw;
                return cleaned;
            }

            async function extractFramesAndContext(markdown, videoFile) {
                const timestampRegex = /\[screenshot:(\d{2}):(\d{2}):(\d{2})\]/g;
                const matches = [...markdown.matchAll(timestampRegex)];
                const successfulFrames = [];
                let cleanedMarkdown = markdown;

                const videoElement = await createVideoElementFromFile(videoFile);
                const canvas = document.createElement('canvas');
                canvas.width = videoElement.width;
                canvas.height = videoElement.height;
                const context = canvas.getContext('2d');

                if (matches.length > 0) {
                    progressText.textContent = `Pass 1/2: Found ${matches.length} key moments. Extracting frames...`;
                    for (let i = 0; i < matches.length; i++) {
                        if (abortController.signal.aborted) throw new DOMException("Aborted", "AbortError");

                        const match = matches[i];
                        const [fullMatch, hh, mm, ss] = match;
                        const timeInSeconds = parseInt(hh) * 3600 + parseInt(mm) * 60 + parseInt(ss);

                        const contextChars = 300;
                        const tagIndex = match.index;
                        const startIndex = Math.max(0, tagIndex - contextChars);
                        const endIndex = Math.min(markdown.length, tagIndex + contextChars);
                        const context = markdown.substring(startIndex, endIndex);

                        try {
                            console.log(`Extracting frame at ${hh}:${mm}:${ss}...`);
                            const frameDataUrl = await extractFrameAtTime(videoElement, timeInSeconds, canvas, context);
                            successfulFrames.push({
                                tag: fullMatch,
                                dataUrl: frameDataUrl,
                                context: context
                            });
                            console.log(` -> Success.`);
                        } catch (e) {
                            console.warn(` -> Failed to extract frame at ${hh}:${mm}:${ss}, removing tag. Error: ${e.message}`);
                            cleanedMarkdown = cleanedMarkdown.replace(fullMatch, '');
                        }
                    }
                }
                return { frames: successfulFrames, cleanedMarkdown };
            }

            async function getRefinedCaptionsInParallel(apiKey, framesWithContext) {
                progressText.textContent = `Pass 2/2: Refining captions for ${framesWithContext.length} screenshots...`;
                // Use the faster, cheaper Flash model for the simple captioning tasks.
                const genAI = new GoogleGenerativeAI(apiKey);
                const model = genAI.getGenerativeModel({ model: "gemini-2.5-flash" });

                const captionPromises = framesWithContext.map((frame, index) => {
                    const prompt = `You are a visual analyst. Based on the provided image and its surrounding text context, write a single, concise, meaningful, one-sentence caption. The caption should describe the visual content and explain its relevance to the topic being discussed. Respond with only the caption text, nothing else.

Context from transcript:
---
${frame.context}
---
`;
                    const imagePart = {
                        inlineData: {
                            mimeType: 'image/jpeg',
                            data: frame.dataUrl.split(',')[1]
                        }
                    };

                    return generateContentWithRetry(model, [prompt, imagePart], 5, `Caption ${index + 1}/${framesWithContext.length} (Flash Model)`)
                        .then(result => {
                            const captionText = result.response.text();
                            console.log(`Caption ${index + 1}: "${captionText.trim()}"`);
                            return captionText;
                        })
                        .catch(err => {
                            console.error(`Caption ${index + 1} failed after all retries:`, err);
                            return "A key visual from the video."; // Fallback caption
                        });
                });

                return Promise.all(captionPromises);
            }


            function assembleFinalMarkdown(markdown, frames, captions) {
                let tempMarkdown = markdown;
                if (frames.length === captions.length) {
                    for (let i = 0; i < frames.length; i++) {
                        const frame = frames[i];
                        const caption = captions[i].replace(/"/g, '').trim();
                        const imageMarkdown = `\n![${caption}](${frame.dataUrl})\n*${caption}*`;
                        tempMarkdown = tempMarkdown.replace(frame.tag, imageMarkdown);
                    }
                }
                return tempMarkdown;
            }

            function extractFrameAtTime(video, timeInSeconds, canvas, context) {
                return new Promise((resolve, reject) => {
                    let timeoutId;

                    const cleanup = () => {
                        clearTimeout(timeoutId);
                        video.onseeked = null;
                    };

                    const drawFrame = () => {
                        try {
                            context.drawImage(video, 0, 0, canvas.width, canvas.height);
                            resolve(canvas.toDataURL("image/jpeg"));
                        } catch (err) {
                            reject(err);
                        } finally {
                            cleanup();
                        }
                    };

                    video.onseeked = () => {
                        if ('requestVideoFrameCallback' in video) {
                            video.requestVideoFrameCallback(() => drawFrame());
                        } else {
                            drawFrame(); // Fallback
                        }
                    };

                    timeoutId = setTimeout(() => {
                        cleanup();
                        reject(new Error("Frame extraction timed out"));
                    }, 10000);

                    video.currentTime = timeInSeconds;
                });
            }

            function handleError(message) {
                errorDiv.textContent = `Error: ${message}`;
                finalizeUI(false);
            }

            function updateProcessButtonState() {
                processBtn.disabled = !localStorage.getItem('geminiApiKey');
            }

            function setInputsDisabled(disabled) {
                videoUploadInput.disabled = disabled;
            }

            function showConfirmationModal() {
                confirmationModal.classList.remove('hidden');
            }

            function hideConfirmationModal() {
                confirmationModal.classList.add('hidden');
            }

            function createVideoElementFromFile(file) {
                return new Promise((resolve, reject) => {
                    const url = URL.createObjectURL(file);
                    const video = document.createElement('video');
                    video.preload = 'auto';
                    video.crossOrigin = 'anonymous';
                    video.src = url;

                    video.onloadedmetadata = () => {
                        video.width = video.videoWidth;
                        video.height = video.videoHeight;
                        resolve(video);
                    };

                    video.onerror = (e) => reject(new Error("Failed to load video element."));
                });
            }
        });
    </script>
</body>

</html>