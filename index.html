<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Video-to-Transcript Summarizer</title>
    <script src="https://cdn.tailwindcss.com?plugins=typography"></script>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">
    <style>
        body {
            font-family: 'Inter', sans-serif;
        }
        .loader {
            border-top-color: #3498db;
            -webkit-animation: spin 1s linear infinite;
            animation: spin 1s linear infinite;
        }
        @keyframes spin {
            0% { transform: rotate(0deg); }
            100% { transform: rotate(360deg); }
        }
        #confirmationModal, #aboutModal {
            transition: opacity 0.3s ease;
        }
        .prose img {
            border-radius: 0.5rem;
            box-shadow: 0 4px 6px -1px rgb(0 0 0 / 0.1), 0 2px 4px -2px rgb(0 0 0 / 0.1);
            margin-left: auto;
            margin-right: auto;
            display: block;
        }
        .prose em {
            color: #6b7280;
            display: block;
            text-align: center;
            font-style: italic;
        }
    </style>
</head>
<body class="bg-gray-50 text-gray-800">

    <div class="container mx-auto max-w-4xl px-4 py-8">
        <header class="text-center mb-8">
            <h1 class="text-4xl font-bold text-gray-900">Video-to-Transcript Summarizer</h1>
            <p class="text-lg text-gray-600 mt-2">Get transcripts with visual context from your videos.</p>
        </header>

        <main>
            <div class="bg-white p-6 rounded-xl shadow-md mb-6">
                <h2 class="text-2xl font-semibold mb-4 text-gray-800">Step 1: Your Gemini API Key</h2>
                <p class="text-gray-600 mb-4">Your API key is stored securely in your browser's local storage.</p>
                <form id="apiKeyForm" onsubmit="return false;">
                    <div class="flex items-center space-x-2">
                        <input type="password" id="apiKey" placeholder="Enter your Gemini API Key" class="flex-grow p-3 border border-gray-300 rounded-lg focus:ring-2 focus:ring-blue-500 focus:outline-none transition">
                        <button id="saveApiKey" type="submit" class="bg-blue-600 text-white font-semibold py-3 px-6 rounded-lg hover:bg-blue-700 transition">Save Key</button>
                    </div>
                </form>
                 <p id="apiKeyStatus" class="text-sm mt-2 text-green-600"></p>
            </div>

            <div class="bg-white p-6 rounded-xl shadow-md mb-6">
                <h2 class="text-2xl font-semibold mb-4 text-gray-800">Step 2: Upload a Video</h2>
                 <div class="flex flex-col items-center justify-center bg-gray-50 p-6 rounded-lg border-2 border-dashed border-gray-300">
                     <label for="videoUpload" class="block text-lg font-medium text-gray-700 mb-2">Upload a Video (.mp4)</label>
                    <input type="file" id="videoUpload" accept="video/mp4" class="w-full text-sm text-gray-500
                        file:mr-4 file:py-2 file:px-4
                        file:rounded-full file:border-0
                        file:text-sm file:font-semibold
                        file:bg-blue-50 file:text-blue-700
                        hover:file:bg-blue-100
                        disabled:opacity-50
                    ">
                    <p id="fileName" class="text-sm mt-2 text-gray-500"></p>
                </div>
            </div>

            <div class="text-center mb-8">
                <button id="processBtn" class="bg-green-600 text-white font-bold py-4 px-8 rounded-lg text-lg hover:bg-green-700 transition shadow-lg disabled:bg-gray-400 disabled:cursor-not-allowed" disabled>
                    Process Video
                </button>
            </div>

            <div id="outputSection" class="bg-white p-6 rounded-xl shadow-md hidden">
                 <div class="flex justify-between items-center mb-4">
                    <h2 class="text-2xl font-semibold text-gray-800">Result</h2>
                    <div id="downloadButtons" class="hidden">
                        <button id="downloadMd" class="bg-gray-700 text-white font-semibold py-2 px-4 rounded-lg hover:bg-gray-800 transition text-sm">Download .md</button>
                        <button id="downloadPdf" class="bg-blue-600 text-white font-semibold py-2 px-4 rounded-lg hover:bg-blue-700 transition text-sm ml-2">Download .pdf</button>
                    </div>
                </div>

                <div id="loadingIndicator" class="text-center py-8 hidden">
                    <div class="loader ease-linear rounded-full border-8 border-t-8 border-gray-200 h-24 w-24 mx-auto"></div>
                    <p id="progressText" class="mt-4 text-lg text-gray-600">Processing video...</p>
                    <button id="interruptBtn" class="mt-4 bg-red-600 text-white font-semibold py-2 px-4 rounded-lg hover:bg-red-700 transition">Interrupt</button>
                </div>

                <div id="result" class="prose max-w-none prose-indigo"></div>
                <div id="error" class="text-red-500 mt-4"></div>
            </div>
        </main>
        
        <footer class="text-center mt-12 text-gray-500 text-sm">
            <button id="aboutBtn" class="underline hover:text-blue-600">About this App</button>
            <p class="mt-2">Created by <a href="mailto:brunjlar@gmail.com" class="underline hover:text-blue-600">Lars Br√ºnjes</a> | <a href="https://github.com/brunjlar/ai-video-overview" target="_blank" rel="noopener noreferrer" class="underline hover:text-blue-600">View on GitHub</a></p>
        </footer>
    </div>

    <div id="aboutModal" class="fixed inset-0 bg-gray-900 bg-opacity-75 flex items-center justify-center p-4 hidden z-50">
        <div class="bg-white rounded-xl shadow-2xl p-8 max-w-2xl w-full relative">
            <button id="closeAboutBtn" class="absolute top-4 right-4 text-gray-500 hover:text-gray-800 text-2xl">&times;</button>
            <div class="prose max-w-none">
                <h2>About the Video-to-Transcript Summarizer</h2>
                <p>This application leverages the power of Google's Gemini AI to transform video content into structured, readable, and context-rich documents. It's designed for students, researchers, and anyone who needs to quickly extract and understand the key information from educational videos, lectures, or talks.</p>
                <h3>How It Works</h3>
                <p>The process happens entirely within your browser, ensuring your data and API key remain private. It uses a sophisticated two-pass workflow to generate high-quality results:</p>
                <ol>
                    <li><strong>Pass 1: Document Structuring:</strong> When you upload a video, the app first sends it to the Gemini 1.5 Flash model. The AI is instructed to analyze the entire video and return a single, well-structured Markdown document. This document includes an overall summary, a list of key takeaways, and the full transcript, correctly divided into chapters with individual summaries. It also identifies 10-15 of the most critical visual moments and inserts simple `[screenshot:...]` placeholder tags at the correct positions within the transcript.</li>
                    <li><strong>Pass 2: Contextual Captioning:</strong> The app then extracts the video frames for each placeholder. In a series of parallel requests, it sends each frame *along with the surrounding text from the transcript* back to the AI. This crucial step provides the necessary context for the AI to generate a meaningful, relevant caption for each image.</li>
                    <li><strong>Final Assembly:</strong> Finally, the app assembles the final document by replacing the placeholders in the text from Pass 1 with the high-quality captions and images from Pass 2, using proper Markdown syntax. This complete document is then rendered on the screen for you to read, review, and download.</li>
                </ol>
                <h3>Why this approach?</h3>
                <p>This two-pass, client-side architecture is designed to be both powerful and private. By breaking the complex task into smaller, focused requests, we get a much more reliable and high-quality result than a single, monolithic request could provide. All processing happens on your machine, so your video data is only ever sent directly to the Google AI API via your own key.</p>
            </div>
        </div>
    </div>


    <script src="https://cdnjs.cloudflare.com/ajax/libs/html2pdf.js/0.10.1/html2pdf.bundle.min.js"></script>
    <script type="module">
        import { GoogleGenerativeAI } from "https://esm.run/@google/generative-ai";
        import { marked } from "https://esm.run/marked";

        document.addEventListener('DOMContentLoaded', () => {
            // --- Element Selectors ---
            const apiKeyForm = document.getElementById('apiKeyForm');
            const apiKeyInput = document.getElementById('apiKey');
            const apiKeyStatus = document.getElementById('apiKeyStatus');
            const videoUploadInput = document.getElementById('videoUpload');
            const fileNameDisplay = document.getElementById('fileName');
            const processBtn = document.getElementById('processBtn');
            const outputSection = document.getElementById('outputSection');
            const loadingIndicator = document.getElementById('loadingIndicator');
            const progressText = document.getElementById('progressText');
            const interruptBtn = document.getElementById('interruptBtn');
            const resultDiv = document.getElementById('result');
            const errorDiv = document.getElementById('error');
            const downloadButtons = document.getElementById('downloadButtons');
            const downloadMdBtn = document.getElementById('downloadMd');
            const downloadPdfBtn = document.getElementById('downloadPdf');
            const aboutBtn = document.getElementById('aboutBtn');
            const aboutModal = document.getElementById('aboutModal');
            const closeAboutBtn = document.getElementById('closeAboutBtn');

            // --- State Variables ---
            let hasResult = false;
            let finalMarkdown = '';
            let abortController;

            // --- Initialization ---
            const storedApiKey = localStorage.getItem('geminiApiKey');
            if (storedApiKey) {
                apiKeyInput.value = '********' + storedApiKey.slice(-4);
                apiKeyStatus.textContent = 'API Key loaded from local storage.';
            } else {
                apiKeyStatus.textContent = 'Please enter your Gemini API Key to enable processing.';
            }
            updateProcessButtonState();

            // --- Event Listeners ---
            apiKeyForm.addEventListener('submit', (event) => {
                event.preventDefault();
                const key = apiKeyInput.value.trim();
                if (key) {
                    localStorage.setItem('geminiApiKey', key);
                    apiKeyStatus.textContent = 'API Key saved successfully!';
                    apiKeyInput.value = '********' + key.slice(-4);
                } else {
                    localStorage.removeItem('geminiApiKey');
                    apiKeyStatus.textContent = 'API Key removed. Please enter a key to enable processing.';
                }
                updateProcessButtonState();
            });
            
            apiKeyInput.addEventListener('focus', () => {
                const storedKey = localStorage.getItem('geminiApiKey');
                if (storedKey) apiKeyInput.value = storedKey;
            });
            apiKeyInput.addEventListener('blur', () => {
                const storedKey = localStorage.getItem('geminiApiKey');
                 if (storedKey) apiKeyInput.value = '********' + storedKey.slice(-4);
            });

            videoUploadInput.addEventListener('change', () => {
                if (videoUploadInput.files.length > 0) {
                    fileNameDisplay.textContent = `Selected file: ${videoUploadInput.files[0].name}`;
                }
            });
            
            processBtn.addEventListener('click', () => {
                if (hasResult) {
                    showConfirmationModal();
                } else {
                    startProcessing();
                }
            });

            interruptBtn.addEventListener('click', () => {
                if (abortController) {
                    abortController.abort("User interrupted processing.");
                }
            });

            aboutBtn.addEventListener('click', () => aboutModal.classList.remove('hidden'));
            closeAboutBtn.addEventListener('click', () => aboutModal.classList.add('hidden'));
            aboutModal.addEventListener('click', (e) => {
                if (e.target === aboutModal) {
                    aboutModal.classList.add('hidden');
                }
            });
            
            downloadMdBtn.addEventListener('click', () => {
                const blob = new Blob([finalMarkdown], { type: 'text/markdown' });
                const url = URL.createObjectURL(blob);
                const a = document.createElement('a');
                a.href = url;
                a.download = 'transcript.md';
                document.body.appendChild(a);
                a.click();
                document.body.removeChild(a);
                URL.revokeObjectURL(url);
            });
            
            downloadPdfBtn.addEventListener('click', () => {
                const element = document.getElementById('result');
                const opt = {
                    margin:       0.5,
                    filename:     'transcript.pdf',
                    image:        { type: 'jpeg', quality: 0.98 },
                    html2canvas:  { scale: 2, useCORS: true },
                    jsPDF:        { unit: 'in', format: 'letter', orientation: 'portrait' }
                };
                html2pdf().set(opt).from(element).save();
            });

            // --- Main Processing Logic ---
            async function startProcessing() {
                console.info("===== PROCESSING STARTED =====");
                resetUI();
                const currentApiKey = localStorage.getItem('geminiApiKey');
                const videoFile = videoUploadInput.files[0];

                if (!validateInputs(currentApiKey, videoFile)) {
                    console.error("Input validation failed. Aborting.");
                    return;
                }
                
                abortController = new AbortController();

                try {
                    // PASS 1: Get the structured markdown with placeholders
                    console.info("--- PASS 1: GETTING STRUCTURED MARKDOWN ---");
                    const preliminaryMarkdown = await getStructuredMarkdown(currentApiKey, videoFile);
                    console.log("Received preliminary markdown from API:", preliminaryMarkdown);
                    
                    // FRAME EXTRACTION
                    console.info("--- FRAME EXTRACTION ---");
                    const { frames, cleanedMarkdown } = await extractFramesAndContext(preliminaryMarkdown, videoFile);
                     console.info(`Found ${frames.length} valid screenshot tags.`)

                    // PASS 2: Get refined, context-aware captions for each frame in parallel
                    if (frames.length > 0) {
                        console.info(`--- PASS 2: GETTING ${frames.length} CAPTIONS ---`);
                        const refinedCaptions = await getRefinedCaptionsInParallel(currentApiKey, frames);
                        finalMarkdown = assembleFinalMarkdown(cleanedMarkdown, frames, refinedCaptions);
                    } else {
                        progressText.textContent = "No key moments identified. Assembling text-only document...";
                         console.info("No valid screenshot tags found. Skipping caption generation.");
                        finalMarkdown = cleanedMarkdown.replace(/\[screenshot:.*?\]/g, ''); // Clean up any stray tags
                    }
                    
                     console.info("--- FINAL ASSEMBLY ---");
                    resultDiv.innerHTML = marked.parse(finalMarkdown);
                    finalizeUI(true);
                     console.info("===== PROCESSING FINISHED SUCCESSFULLY =====");

                } catch (error) {
                    if (error.name === 'AbortError') {
                        handleError('Processing was interrupted by the user.');
                         console.warn("Processing was interrupted by the user.");
                    } else {
                        handleError(error.message);
                         console.error("An unrecoverable error occurred:", error);
                    }
                     console.error("===== PROCESSING FAILED =====");
                }
            }

            // --- Helper Functions ---

            function resetUI() {
                hasResult = false;
                finalMarkdown = '';
                errorDiv.textContent = '';
                resultDiv.innerHTML = '';
                outputSection.classList.remove('hidden');
                loadingIndicator.classList.remove('hidden');
                downloadButtons.classList.add('hidden');
                processBtn.disabled = true;
                setInputsDisabled(true);
                progressText.textContent = 'Initializing...';
            }

            function validateInputs(apiKey, file) {
                if (!apiKey) {
                    handleError('Please save your Gemini API Key first.');
                    return false;
                }
                if (!file) {
                    handleError('Please upload a video file.');
                    return false;
                }
                return true;
            }

            function finalizeUI(success) {
                loadingIndicator.classList.add('hidden');
                updateProcessButtonState();
                setInputsDisabled(false);
                if (success) {
                    downloadButtons.classList.remove('hidden');
                    hasResult = true; 
                    videoUploadInput.value = '';
                    fileNameDisplay.textContent = '';
                }
            }

            async function fileToGenerativePart(file) {
                const base64EncodedDataPromise = new Promise((resolve) => {
                    const reader = new FileReader();
                    reader.onloadend = () => resolve(reader.result.split(',')[1]);
                    reader.readAsDataURL(file);
                });
                return {
                    inlineData: { data: await base64EncodedDataPromise, mimeType: file.type },
                };
            }

            async function generateContentWithRetry(model, prompt, maxRetries = 5, requestName = "Generic") {
                let lastError;
                for (let i = 0; i < maxRetries; i++) {
                    if (abortController && abortController.signal.aborted) {
                        throw new DOMException("Aborted by user", "AbortError");
                    }
                    try {
                        console.log(`[API Request: ${requestName}] Attempt ${i + 1}/${maxRetries}...`);
                        const result = await model.generateContent(prompt);
                        console.log(`[API Request: ${requestName}] Success.`);
                        return result;
                    } catch (error) {
                        lastError = error;
                        if (error.toString().includes('503') || error.toString().includes('overloaded')) {
                            const delay = (2 ** i * 1000) + (Math.random() * 1000);
                            console.warn(`[API Request: ${requestName}] Failed (attempt ${i + 1}/${maxRetries}). Retrying in ${Math.round(delay)}ms...`);
                            await new Promise(resolve => setTimeout(resolve, delay));
                        } else {
                             console.error(`[API Request: ${requestName}] Failed with non-retryable error:`, error);
                            throw error;
                        }
                    }
                }
                 console.error(`[API Request: ${requestName}] Failed after all ${maxRetries} attempts.`);
                throw new Error(`API call failed after ${maxRetries} attempts. Last error: ${lastError}`);
            }


            async function getStructuredMarkdown(apiKey, file) {
                const genAI = new GoogleGenerativeAI(apiKey);
                // FIX: Use the more powerful Pro model for this complex, high-stakes task.
                const model = genAI.getGenerativeModel({ model: "gemini-2.5-pro" });

                progressText.textContent = "Pass 1/2: Analyzing video and generating document structure...";
                const videoPart = await fileToGenerativePart(file);
                
                const prompt = `
You are an expert technical writer and video analyst. 
Your task is to create a single, comprehensive document from the provided video, formatted in Markdown.

Follow this exact structure:

1.  Create a main heading '# [Video Title]' with the title of the video.
2.  Create a heading '## Overall Summary' and write a one-paragraph summary of the entire video.
3.  Create a heading '## Key Takeaways' and write a bulleted list of the 3-5 most important points.
4.  Then, identify the logical chapters in the video. For each chapter, you MUST create the following block:
    - A subheading: '### Chapter: [Chapter Title]'
    - A one-paragraph summary of that chapter.
    - The full, clean transcript for that chapter.
    - CRUCIALLY: As you write the transcript, you MUST insert a placeholder tag on its own line 
      (with an empty line before and after) immediately after the sentence that references a key visual moment.
    - The tag format is: [screenshot:HH:MM:SS]

    For example:
    > This is a sentence in the transcript that refers to a diagram.
    >
    > [screenshot:01:23:45]
    >
    > The transcript then continues with the next sentence.

    Pick those "key visual moments" that are most relevant to understanding the video's content, especially those
    that are not already obvious from the transcript alone.

Select 10-15 of the most critical visual moments.
The response must be PURE MARKDOWN. Do not add any conversational text like "Certainly, here is your markdown."
Your output should therefore start with

# [Video Title]

## Overall Summary

and end with the last chapter's transcript. Nothing else. Just Markdown.

This, for example, would be invalid:

----

Of course! Here is a detailed JSON-formatted description of the events in the video.

\`\`\`json ...

-----

The "Of course! Here is..." is not part of the Markdown document. Neither is the \`\`\`\`json\` block.
And - of course - json is not Markdown.
`;
                const result = await generateContentWithRetry(model, [prompt, videoPart], 5, "Initial Structure (Pro Model)");
                return result.response.text();
            }
            
            async function extractFramesAndContext(markdown, videoFile) {
                const timestampRegex = /\[screenshot:(\d{2}):(\d{2}):(\d{2})\]/g;
                const matches = [...markdown.matchAll(timestampRegex)];
                const successfulFrames = [];
                let cleanedMarkdown = markdown;

                if (matches.length > 0) {
                    progressText.textContent = `Pass 1/2: Found ${matches.length} key moments. Extracting frames...`;
                    for (let i = 0; i < matches.length; i++) {
                        if (abortController.signal.aborted) throw new DOMException("Aborted", "AbortError");
                        
                        const match = matches[i];
                        const [fullMatch, hh, mm, ss] = match;
                        const timeInSeconds = parseInt(hh) * 3600 + parseInt(mm) * 60 + parseInt(ss);
                        
                        const contextChars = 300;
                        const tagIndex = match.index;
                        const startIndex = Math.max(0, tagIndex - contextChars);
                        const endIndex = Math.min(markdown.length, tagIndex + contextChars);
                        const context = markdown.substring(startIndex, endIndex);

                        try {
                            console.log(`Extracting frame at ${hh}:${mm}:${ss}...`);
                            const frameDataUrl = await extractFrameAtTime(videoFile, timeInSeconds);
                            successfulFrames.push({
                                tag: fullMatch,
                                dataUrl: frameDataUrl,
                                context: context
                            });
                             console.log(` -> Success.`);
                        } catch (e) {
                             console.warn(` -> Failed to extract frame at ${hh}:${mm}:${ss}, removing tag. Error: ${e.message}`);
                            cleanedMarkdown = cleanedMarkdown.replace(fullMatch, '');
                        }
                    }
                }
                return { frames: successfulFrames, cleanedMarkdown };
            }

            async function getRefinedCaptionsInParallel(apiKey, framesWithContext) {
                progressText.textContent = `Pass 2/2: Refining captions for ${framesWithContext.length} screenshots...`;
                // Use the faster, cheaper Flash model for the simple captioning tasks.
                const genAI = new GoogleGenerativeAI(apiKey);
                const model = genAI.getGenerativeModel({ model: "gemini-2.5-flash" });

                const captionPromises = framesWithContext.map((frame, index) => {
                    const prompt = `You are a visual analyst. Based on the provided image and its surrounding text context, write a single, concise, meaningful, one-sentence caption. The caption should describe the visual content and explain its relevance to the topic being discussed. Respond with only the caption text, nothing else.

Context from transcript:
---
${frame.context}
---
`;
                    const imagePart = {
                        inlineData: {
                            mimeType: 'image/jpeg',
                            data: frame.dataUrl.split(',')[1]
                        }
                    };
                    
                    return generateContentWithRetry(model, [prompt, imagePart], 5, `Caption ${index + 1}/${framesWithContext.length} (Flash Model)`)
                        .then(result => {
                            const captionText = result.response.text();
                             console.log(`Caption ${index + 1}: "${captionText.trim()}"`);
                            return captionText;
                        })
                        .catch(err => {
                             console.error(`Caption ${index + 1} failed after all retries:`, err);
                            return "A key visual from the video."; // Fallback caption
                        });
                });

                return Promise.all(captionPromises);
            }


            function assembleFinalMarkdown(markdown, frames, captions) {
                let tempMarkdown = markdown;
                if (frames.length === captions.length) {
                    for (let i = 0; i < frames.length; i++) {
                        const frame = frames[i];
                        const caption = captions[i].replace(/"/g, '').trim();
                        const imageMarkdown = `\n![${caption}](${frame.dataUrl})\n*${caption}*`;
                        tempMarkdown = tempMarkdown.replace(frame.tag, imageMarkdown);
                    }
                }
                return tempMarkdown;
            }

            function extractFrameAtTime(file, timeInSeconds) {
                return new Promise((resolve, reject) => {
                    const timeout = 10000; // 10-second timeout per frame

                    let timeoutId = setTimeout(() => {
                        cleanup();
                        reject(new Error(`Frame extraction timed out after ${timeout / 1000} seconds.`));
                    }, timeout);

                    const video = document.createElement('video');
                    const canvas = document.createElement('canvas');
                    const context = canvas.getContext('2d');
                    let objectUrl = URL.createObjectURL(file);
                    
                    const cleanup = () => {
                        clearTimeout(timeoutId);
                        if (objectUrl) {
                            URL.revokeObjectURL(objectUrl);
                            objectUrl = null;
                        }
                        video.src = '';
                        video.load();
                    };

                    video.onloadedmetadata = () => {
                        canvas.width = video.videoWidth;
                        canvas.height = video.videoHeight;
                        video.currentTime = timeInSeconds;
                    };

                    video.onseeked = () => {
                        if (video.currentTime >= timeInSeconds) {
                            context.drawImage(video, 0, 0, canvas.width, canvas.height);
                            const dataUrl = canvas.toDataURL('image/jpeg');
                            cleanup();
                            resolve(dataUrl);
                        }
                    };

                    video.onerror = (e) => {
                        cleanup();
                        reject(new Error('Failed to load or seek video. The file may be corrupted.'));
                    };

                    video.src = objectUrl;
                    video.muted = true;
                });
            }

            function handleError(message) {
                errorDiv.textContent = `Error: ${message}`;
                finalizeUI(false);
            }

            function updateProcessButtonState() {
                processBtn.disabled = !localStorage.getItem('geminiApiKey');
            }

            function setInputsDisabled(disabled) {
                videoUploadInput.disabled = disabled;
            }

            function showConfirmationModal() {
                confirmationModal.classList.remove('hidden');
            }

            function hideConfirmationModal() {
                confirmationModal.classList.add('hidden');
            }
        });
    </script>
</body>
</html>