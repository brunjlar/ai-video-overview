<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Video-to-Transcript Summarizer</title>
    <script src="https://cdn.tailwindcss.com?plugins=typography"></script>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">
    <style>
        body {
            font-family: 'Inter', sans-serif;
        }
        .loader {
            border-top-color: #3498db;
            -webkit-animation: spin 1s linear infinite;
            animation: spin 1s linear infinite;
        }
        @keyframes spin {
            0% { transform: rotate(0deg); }
            100% { transform: rotate(360deg); }
        }
        #confirmationModal {
            transition: opacity 0.3s ease;
        }
        .prose img {
            border-radius: 0.5rem;
            box-shadow: 0 4px 6px -1px rgb(0 0 0 / 0.1), 0 2px 4px -2px rgb(0 0 0 / 0.1);
            margin-left: auto;
            margin-right: auto;
            display: block;
        }
    </style>
</head>
<body class="bg-gray-50 text-gray-800">

    <div class="container mx-auto max-w-4xl px-4 py-8">
        <header class="text-center mb-8">
            <h1 class="text-4xl font-bold text-gray-900">Video-to-Transcript Summarizer</h1>
            <p class="text-lg text-gray-600 mt-2">Get transcripts with visual context from your videos.</p>
        </header>

        <main>
            <!-- Step 1: API Key -->
            <div class="bg-white p-6 rounded-xl shadow-md mb-6">
                <h2 class="text-2xl font-semibold mb-4 text-gray-800">Step 1: Your Gemini API Key</h2>
                <p class="text-gray-600 mb-4">Your API key is stored securely in your browser's local storage.</p>
                <form id="apiKeyForm" onsubmit="return false;">
                    <div class="flex items-center space-x-2">
                        <input type="password" id="apiKey" placeholder="Enter your Gemini API Key" class="flex-grow p-3 border border-gray-300 rounded-lg focus:ring-2 focus:ring-blue-500 focus:outline-none transition">
                        <button id="saveApiKey" type="submit" class="bg-blue-600 text-white font-semibold py-3 px-6 rounded-lg hover:bg-blue-700 transition">Save Key</button>
                    </div>
                </form>
                 <p id="apiKeyStatus" class="text-sm mt-2 text-green-600"></p>
            </div>

            <!-- Step 2: Input Video -->
            <div class="bg-white p-6 rounded-xl shadow-md mb-6">
                <h2 class="text-2xl font-semibold mb-4 text-gray-800">Step 2: Provide a Video</h2>
                <div class="grid grid-cols-1 md:grid-cols-2 gap-6">
                    <div>
                        <label for="youtubeUrl" class="block text-lg font-medium text-gray-700 mb-2">YouTube URL</label>
                        <input type="text" id="youtubeUrl" placeholder="YouTube support coming soon..." class="w-full p-3 border border-gray-300 rounded-lg focus:ring-2 focus:ring-blue-500 focus:outline-none transition disabled:bg-gray-200" disabled>
                    </div>
                    <div class="flex flex-col items-center justify-center bg-gray-50 p-6 rounded-lg border-2 border-dashed border-gray-300">
                         <label for="videoUpload" class="block text-lg font-medium text-gray-700 mb-2">Upload a Video (.mp4)</label>
                        <input type="file" id="videoUpload" accept="video/mp4" class="w-full text-sm text-gray-500
                            file:mr-4 file:py-2 file:px-4
                            file:rounded-full file:border-0
                            file:text-sm file:font-semibold
                            file:bg-blue-50 file:text-blue-700
                            hover:file:bg-blue-100
                            disabled:opacity-50
                        ">
                        <p id="fileName" class="text-sm mt-2 text-gray-500"></p>
                    </div>
                </div>
            </div>

            <!-- Step 3: Process -->
            <div class="text-center mb-8">
                <button id="processBtn" class="bg-green-600 text-white font-bold py-4 px-8 rounded-lg text-lg hover:bg-green-700 transition shadow-lg disabled:bg-gray-400 disabled:cursor-not-allowed" disabled>
                    Process Video
                </button>
            </div>

            <!-- Step 4: Output -->
            <div id="outputSection" class="bg-white p-6 rounded-xl shadow-md hidden">
                 <div class="flex justify-between items-center mb-4">
                    <h2 class="text-2xl font-semibold text-gray-800">Result</h2>
                    <div id="downloadButtons" class="hidden">
                        <button id="downloadMd" class="bg-gray-700 text-white font-semibold py-2 px-4 rounded-lg hover:bg-gray-800 transition text-sm">Download .md</button>
                    </div>
                </div>

                <div id="loadingIndicator" class="text-center py-8 hidden">
                    <div class="loader ease-linear rounded-full border-8 border-t-8 border-gray-200 h-24 w-24 mx-auto"></div>
                    <p id="progressText" class="mt-4 text-lg text-gray-600">Processing video...</p>
                    <button id="interruptBtn" class="mt-4 bg-red-600 text-white font-semibold py-2 px-4 rounded-lg hover:bg-red-700 transition">Interrupt</button>
                </div>

                <div id="result" class="prose max-w-none prose-indigo"></div>
                <div id="error" class="text-red-500 mt-4"></div>
            </div>
        </main>
    </div>

    <!-- Confirmation Modal -->
    <div id="confirmationModal" class="fixed inset-0 bg-gray-900 bg-opacity-50 flex items-center justify-center p-4 hidden z-50">
        <div class="bg-white rounded-xl shadow-2xl p-8 max-w-md w-full">
            <h3 class="text-2xl font-bold text-gray-900 mb-4">Start New Process?</h3>
            <p class="text-gray-600 mb-6">Starting a new process will clear your current results. Please make sure you have downloaded your work before proceeding.</p>
            <div class="flex justify-end space-x-4">
                <button id="cancelProceedBtn" class="bg-gray-200 text-gray-800 font-semibold py-2 px-6 rounded-lg hover:bg-gray-300 transition">Cancel</button>
                <button id="confirmProceedBtn" class="bg-red-600 text-white font-semibold py-2 px-6 rounded-lg hover:bg-red-700 transition">Proceed</button>
            </div>
        </div>
    </div>


    <script type="module">
        import { GoogleGenerativeAI } from "https://esm.run/@google/generative-ai";
        import { marked } from "https://esm.run/marked";

        document.addEventListener('DOMContentLoaded', () => {
            // --- Element Selectors ---
            const apiKeyForm = document.getElementById('apiKeyForm');
            const apiKeyInput = document.getElementById('apiKey');
            const apiKeyStatus = document.getElementById('apiKeyStatus');
            const videoUploadInput = document.getElementById('videoUpload');
            const fileNameDisplay = document.getElementById('fileName');
            const processBtn = document.getElementById('processBtn');
            const outputSection = document.getElementById('outputSection');
            const loadingIndicator = document.getElementById('loadingIndicator');
            const progressText = document.getElementById('progressText');
            const interruptBtn = document.getElementById('interruptBtn');
            const resultDiv = document.getElementById('result');
            const errorDiv = document.getElementById('error');
            const downloadButtons = document.getElementById('downloadButtons');
            const confirmationModal = document.getElementById('confirmationModal');
            const confirmProceedBtn = document.getElementById('confirmProceedBtn');
            const cancelProceedBtn = document.getElementById('cancelProceedBtn');
            const downloadMdBtn = document.getElementById('downloadMd');

            // --- State Variables ---
            let hasResult = false;
            let finalMarkdown = '';
            let abortController;

            // --- Initialization ---
            const storedApiKey = localStorage.getItem('geminiApiKey');
            if (storedApiKey) {
                apiKeyInput.value = '********' + storedApiKey.slice(-4);
                apiKeyStatus.textContent = 'API Key loaded from local storage.';
            } else {
                apiKeyStatus.textContent = 'Please enter your Gemini API Key to enable processing.';
            }
            updateProcessButtonState();

            // --- Event Listeners ---
            apiKeyForm.addEventListener('submit', (event) => {
                event.preventDefault();
                const key = apiKeyInput.value.trim();
                if (key) {
                    localStorage.setItem('geminiApiKey', key);
                    apiKeyStatus.textContent = 'API Key saved successfully!';
                    apiKeyInput.value = '********' + key.slice(-4);
                } else {
                    localStorage.removeItem('geminiApiKey');
                    apiKeyStatus.textContent = 'API Key removed. Please enter a key to enable processing.';
                }
                updateProcessButtonState();
            });

            apiKeyInput.addEventListener('focus', () => {
                const storedKey = localStorage.getItem('geminiApiKey');
                if (storedKey) apiKeyInput.value = storedKey;
            });
            apiKeyInput.addEventListener('blur', () => {
                const storedKey = localStorage.getItem('geminiApiKey');
                 if (storedKey) apiKeyInput.value = '********' + storedKey.slice(-4);
            });

            videoUploadInput.addEventListener('change', () => {
                if (videoUploadInput.files.length > 0) {
                    fileNameDisplay.textContent = `Selected file: ${videoUploadInput.files[0].name}`;
                }
            });

            processBtn.addEventListener('click', () => {
                if (hasResult) {
                    showConfirmationModal();
                } else {
                    startProcessing();
                }
            });

            interruptBtn.addEventListener('click', () => {
                if (abortController) {
                    abortController.abort("User interrupted processing.");
                }
            });

            confirmProceedBtn.addEventListener('click', () => {
                hideConfirmationModal();
                startProcessing();
            });
            cancelProceedBtn.addEventListener('click', () => {
                hideConfirmationModal();
            });

            downloadMdBtn.addEventListener('click', () => {
                const blob = new Blob([finalMarkdown], { type: 'text/markdown' });
                const url = URL.createObjectURL(blob);
                const a = document.createElement('a');
                a.href = url;
                a.download = 'transcript.md';
                document.body.appendChild(a);
                a.click();
                document.body.removeChild(a);
                URL.revokeObjectURL(url);
            });

            // --- Main Processing Logic ---
            async function startProcessing() {
                resetUI();
                const currentApiKey = localStorage.getItem('geminiApiKey');
                const videoFile = videoUploadInput.files[0];

                if (!validateInputs(currentApiKey, videoFile)) return;

                abortController = new AbortController();

                try {
                    // PASS 1: Get the structured markdown with placeholders
                    const preliminaryMarkdown = await getStructuredMarkdown(currentApiKey, videoFile);

                    // Extract frames based on placeholders
                    const frames = await extractFrames(preliminaryMarkdown, videoFile);

                    // PASS 2: Get refined, context-aware captions for the extracted frames
                    if (frames.length > 0) {
                        const refinedCaptions = await getRefinedCaptions(currentApiKey, frames, preliminaryMarkdown);
                        finalMarkdown = assembleFinalMarkdown(preliminaryMarkdown, frames, refinedCaptions);
                    } else {
                        progressText.textContent = "No key moments identified. Displaying text-only document...";
                        finalMarkdown = preliminaryMarkdown.replace(/\[screenshot:.*?\]/g, ''); // Clean up any stray tags
                    }

                    resultDiv.innerHTML = marked.parse(finalMarkdown);
                    finalizeUI(true);

                } catch (error) {
                    if (error.name === 'AbortError') {
                        handleError('Processing was interrupted by the user.');
                    } else {
                        handleError(error.message);
                    }
                }
            }

            // --- Helper Functions ---

            function resetUI() {
                hasResult = false;
                finalMarkdown = '';
                errorDiv.textContent = '';
                resultDiv.innerHTML = '';
                outputSection.classList.remove('hidden');
                loadingIndicator.classList.remove('hidden');
                downloadButtons.classList.add('hidden');
                processBtn.disabled = true;
                setInputsDisabled(true);
                progressText.textContent = 'Initializing...';
            }

            function validateInputs(apiKey, file) {
                if (!apiKey) {
                    handleError('Please save your Gemini API Key first.');
                    return false;
                }
                if (!file) {
                    handleError('Please upload a video file.');
                    return false;
                }
                return true;
            }

            function finalizeUI(success) {
                loadingIndicator.classList.add('hidden');
                updateProcessButtonState();
                setInputsDisabled(false);
                if (success) {
                    downloadButtons.classList.remove('hidden');
                    hasResult = true;
                    videoUploadInput.value = '';
                    fileNameDisplay.textContent = '';
                }
            }

            async function fileToGenerativePart(file) {
                const base64EncodedDataPromise = new Promise((resolve) => {
                    const reader = new FileReader();
                    reader.onloadend = () => resolve(reader.result.split(',')[1]);
                    reader.readAsDataURL(file);
                });
                return {
                    inlineData: { data: await base64EncodedDataPromise, mimeType: file.type },
                };
            }

            async function getStructuredMarkdown(apiKey, file) {
                const genAI = new GoogleGenerativeAI(apiKey);
                const model = genAI.getGenerativeModel({ model: "gemini-1.5-flash-latest" });

                progressText.textContent = "Pass 1/2: Analyzing video and generating document structure...";
                const videoPart = await fileToGenerativePart(file);

                const prompt = `
You are an expert technical writer and video analyst. Your task is to create a single, comprehensive document from the provided video, formatted in Markdown.

Follow this exact structure:

1.  Create a main heading '## Overall Summary' and write a one-paragraph summary of the entire video.
2.  Create a main heading '## Key Takeaways' and write a bulleted list of the 3-5 most important points.
3.  Then, identify the logical chapters in the video. For each chapter you identify, you MUST repeat the following block:
    - Create a subheading: '### Chapter: [Chapter Title]'
    - Below the heading, write a short, one-paragraph summary of that chapter.
    - Below the summary, provide a clean, accurate, and complete transcript of the spoken content *for that chapter only*.
    - Within that chapter's transcript, when you identify a key visual moment (like a new slide, a diagram, or a demonstration), insert a special tag on its own line: [screenshot:HH:MM:SS | A brief description of what should be in this image and why it's important]

Select no more than 10-15 of the most critical visual moments.
Do NOT add any conversational text, introductions, or concluding remarks. The response must be pure Markdown.
`;
                const result = await model.generateContent([prompt, videoPart]);
                return result.response.text();
            }

            async function extractFrames(markdown, videoFile) {
                const timestampRegex = /\[screenshot:(\d{2}):(\d{2}):(\d{2}) \|.*?\]/g;
                const matches = [...markdown.matchAll(timestampRegex)];
                const frames = [];

                if (matches.length > 0) {
                    progressText.textContent = `Pass 1/2: Found ${matches.length} key moments. Extracting frames...`;
                    for (let i = 0; i < matches.length; i++) {
                        if (abortController.signal.aborted) throw new DOMException("Aborted", "AbortError");
                        const match = matches[i];
                        const [fullMatch, hh, mm, ss] = match;
                        const timeInSeconds = parseInt(hh) * 3600 + parseInt(mm) * 60 + parseInt(ss);

                        try {
                            const frameDataUrl = await extractFrameAtTime(videoFile, timeInSeconds);
                            frames.push({
                                tag: fullMatch,
                                dataUrl: frameDataUrl
                            });
                        } catch (e) {
                            console.error(`Could not extract frame at ${timeInSeconds}s:`, e);
                        }
                    }
                }
                return frames;
            }

            async function getRefinedCaptions(apiKey, frames, originalMarkdown) {
                const genAI = new GoogleGenerativeAI(apiKey);
                const model = genAI.getGenerativeModel({ model: "gemini-1.5-flash-latest" });

                progressText.textContent = `Pass 2/2: Refining captions for ${frames.length} screenshots...`;

                const prompt = `
You are a visual analyst. I will provide a full transcript document that
includes placeholders like [screenshot:...].
I will also provide a series of images that correspond to each placeholder.
Your task is to generate a high-quality,
context-aware caption for each image.

For each image, analyze the image itself and the text immediately
surrounding its placeholder in the transcript.
Write a concise, one-sentence caption that describes the visual content
and explains its relevance to the topic being discussed.

Here is the full transcript for context:

---
` + originalMarkdown + `
---

Now, here are the images in order. Provide your response as a single
JSON array of strings, where each string is the refined caption
for the corresponding image. For example:
[\"Caption for the first image.\", \"Caption for the second image.\"]
`;
                const promptParts = [
                    { text: prompt }
                ];

                for (const frame of frames) {
                    if (abortController.signal.aborted) throw new DOMException("Aborted", "AbortError");
                    promptParts.push({
                        inlineData: {
                            mimeType: 'image/jpeg',
                            data: frame.dataUrl.split(',')[1]
                        }
                    });
                }

                const result = await model.generateContent({
                    contents: [{ parts: promptParts }],
                    generationConfig: { responseMimeType: "application/json" }
                });

                const text = result.response.text();
                // Clean the response to ensure it's valid JSON
                const cleanedText = text.replace(/```json\n?/, '').replace(/```$/, '');
                console.log("Refined captions:", cleanedText);
                return JSON.parse(cleanedText);
            }

            function assembleFinalMarkdown(markdown, frames, captions) {
                let tempMarkdown = markdown;
                if (frames.length === captions.length) {
                    for (let i = 0; i < frames.length; i++) {
                        const frame = frames[i];
                        const caption = captions[i].replace(/"/g, ''); // Clean up quotes
                        const imageMarkdown = `\n![${caption}](${frame.dataUrl})\n*${caption}*`;
                        tempMarkdown = tempMarkdown.replace(frame.tag, imageMarkdown);
                    }
                } else {
                    console.warn("Mismatch between frames and captions. Inserting images without refined captions.");
                     for (const frame of frames) {
                        const imageMarkdown = `\n![Frame without caption](${frame.dataUrl})\n`;
                        tempMarkdown = tempMarkdown.replace(frame.tag, imageMarkdown);
                    }
                }
                return tempMarkdown;
            }

            function extractFrameAtTime(file, timeInSeconds) {
                return new Promise((resolve, reject) => {
                    const video = document.createElement('video');
                    const canvas = document.createElement('canvas');
                    const context = canvas.getContext('2d');

                    video.src = URL.createObjectURL(file);
                    video.muted = true;

                    video.onloadedmetadata = () => {
                        canvas.width = video.videoWidth;
                        canvas.height = video.videoHeight;
                        video.currentTime = timeInSeconds;
                    };

                    video.onseeked = () => {
                        if (video.currentTime >= timeInSeconds) {
                            context.drawImage(video, 0, 0, canvas.width, canvas.height);
                            URL.revokeObjectURL(video.src);
                            resolve(canvas.toDataURL('image/jpeg'));
                        }
                    };

                    video.onerror = (e) => {
                        URL.revokeObjectURL(video.src);
                        reject(new Error('Failed to load or seek video.'));
                    };
                });
            }

            function handleError(message) {
                errorDiv.textContent = `Error: ${message}`;
                finalizeUI(false);
            }

            function updateProcessButtonState() {
                processBtn.disabled = !localStorage.getItem('geminiApiKey');
            }

            function setInputsDisabled(disabled) {
                videoUploadInput.disabled = disabled;
            }

            function showConfirmationModal() {
                confirmationModal.classList.remove('hidden');
            }

            function hideConfirmationModal() {
                confirmationModal.classList.add('hidden');
            }
        });
    </script>
</body>
</html>
