<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Video-to-Transcript Summarizer</title>
    <!-- FIX: Added the typography plugin to the Tailwind CSS script for proper rendering -->
    <script src="https://cdn.tailwindcss.com?plugins=typography"></script>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">
    <style>
        body {
            font-family: 'Inter', sans-serif;
        }
        .loader {
            border-top-color: #3498db;
            -webkit-animation: spin 1s linear infinite;
            animation: spin 1s linear infinite;
        }
        @keyframes spin {
            0% { transform: rotate(0deg); }
            100% { transform: rotate(360deg); }
        }
        #confirmationModal {
            transition: opacity 0.3s ease;
        }
        /* Ensure prose styles apply correctly */
        #result {
            padding: 1rem;
        }
        .prose img {
            border-radius: 0.5rem;
            box-shadow: 0 4px 6px -1px rgb(0 0 0 / 0.1), 0 2px 4px -2px rgb(0 0 0 / 0.1);
            margin-left: auto;
            margin-right: auto;
            display: block;
        }
    </style>
</head>
<body class="bg-gray-50 text-gray-800">

    <div class="container mx-auto max-w-4xl px-4 py-8">
        <header class="text-center mb-8">
            <h1 class="text-4xl font-bold text-gray-900">Video-to-Transcript Summarizer</h1>
            <p class="text-lg text-gray-600 mt-2">Get transcripts with visual context from your videos.</p>
        </header>

        <main>
            <!-- Step 1: API Key -->
            <div class="bg-white p-6 rounded-xl shadow-md mb-6">
                <h2 class="text-2xl font-semibold mb-4 text-gray-800">Step 1: Your Gemini API Key</h2>
                <p class="text-gray-600 mb-4">Your API key is stored securely in your browser's local storage.</p>
                <form id="apiKeyForm" onsubmit="return false;">
                    <div class="flex items-center space-x-2">
                        <input type="password" id="apiKey" placeholder="Enter your Gemini API Key" class="flex-grow p-3 border border-gray-300 rounded-lg focus:ring-2 focus:ring-blue-500 focus:outline-none transition">
                        <button id="saveApiKey" type="submit" class="bg-blue-600 text-white font-semibold py-3 px-6 rounded-lg hover:bg-blue-700 transition">Save Key</button>
                    </div>
                </form>
                 <p id="apiKeyStatus" class="text-sm mt-2 text-green-600"></p>
            </div>

            <!-- Step 2: Input Video -->
            <div class="bg-white p-6 rounded-xl shadow-md mb-6">
                <h2 class="text-2xl font-semibold mb-4 text-gray-800">Step 2: Provide a Video</h2>
                <div class="grid grid-cols-1 md:grid-cols-2 gap-6">
                    <div>
                        <label for="youtubeUrl" class="block text-lg font-medium text-gray-700 mb-2">YouTube URL</label>
                        <input type="text" id="youtubeUrl" placeholder="YouTube support coming soon..." class="w-full p-3 border border-gray-300 rounded-lg focus:ring-2 focus:ring-blue-500 focus:outline-none transition disabled:bg-gray-200" disabled>
                    </div>
                    <div class="flex flex-col items-center justify-center bg-gray-50 p-6 rounded-lg border-2 border-dashed border-gray-300">
                         <label for="videoUpload" class="block text-lg font-medium text-gray-700 mb-2">Upload a Video (.mp4)</label>
                        <input type="file" id="videoUpload" accept="video/mp4" class="w-full text-sm text-gray-500
                            file:mr-4 file:py-2 file:px-4
                            file:rounded-full file:border-0
                            file:text-sm file:font-semibold
                            file:bg-blue-50 file:text-blue-700
                            hover:file:bg-blue-100
                            disabled:opacity-50
                        ">
                        <p id="fileName" class="text-sm mt-2 text-gray-500"></p>
                    </div>
                </div>
            </div>

            <!-- Step 3: Process -->
            <div class="text-center mb-8">
                <button id="processBtn" class="bg-green-600 text-white font-bold py-4 px-8 rounded-lg text-lg hover:bg-green-700 transition shadow-lg disabled:bg-gray-400 disabled:cursor-not-allowed" disabled>
                    Process Video
                </button>
            </div>

            <!-- Step 4: Output -->
            <div id="outputSection" class="bg-white p-6 rounded-xl shadow-md hidden">
                 <div class="flex justify-between items-center mb-4">
                    <h2 class="text-2xl font-semibold text-gray-800">Result</h2>
                    <div id="downloadButtons" class="hidden">
                        <button id="downloadMd" class="bg-gray-700 text-white font-semibold py-2 px-4 rounded-lg hover:bg-gray-800 transition text-sm">Download .md</button>
                        <button id="downloadPdf" class="bg-blue-600 text-white font-semibold py-2 px-4 rounded-lg hover:bg-blue-700 transition text-sm ml-2">Download .pdf</button>
                    </div>
                </div>

                <div id="loadingIndicator" class="text-center py-8 hidden">
                    <div class="loader ease-linear rounded-full border-8 border-t-8 border-gray-200 h-24 w-24 mx-auto"></div>
                    <p id="progressText" class="mt-4 text-lg text-gray-600">Processing video...</p>
                    <button id="interruptBtn" class="mt-4 bg-red-600 text-white font-semibold py-2 px-4 rounded-lg hover:bg-red-700 transition">Interrupt</button>
                </div>

                <div id="result" class="prose max-w-none prose-indigo"></div>
                <div id="error" class="text-red-500 mt-4"></div>
            </div>
        </main>
        
        <footer class="text-center mt-12 text-gray-500 text-sm">
            <button id="aboutBtn" class="underline hover:text-blue-600">About this App</button>
            <p class="mt-2">Created by <a href="mailto:brunjlar@gmail.com" class="underline hover:text-blue-600">Lars Brünjes</a> | <a href="https://github.com/brunjlar/ai-video-overview" target="_blank" rel="noopener noreferrer" class="underline hover:text-blue-600">View on GitHub</a></p>
        </footer>
    </div>

    <!-- About Modal -->
    <div id="aboutModal" class="fixed inset-0 bg-gray-900 bg-opacity-75 flex items-center justify-center p-4 hidden z-50">
        <div class="bg-white rounded-xl shadow-2xl p-8 max-w-2xl w-full relative">
            <button id="closeAboutBtn" class="absolute top-4 right-4 text-gray-500 hover:text-gray-800 text-2xl">&times;</button>
            <div class="prose max-w-none">
                <h2>About the Video-to-Transcript Summarizer</h2>
                <p>This application leverages the power of Google's Gemini AI to transform video content into structured, readable, and context-rich documents. It's designed for students, researchers, and anyone who needs to quickly extract and understand the key information from educational videos, lectures, or talks.</p>
                <h3>How It Works</h3>
                <p>The process happens entirely within your browser, ensuring your data and API key remain private. Here's the multi-pass workflow:</p>
                <ol>
                    <li><strong>Initial Analysis:</strong> When you upload a video, the app first sends it to the Gemini 1.5 Flash model. The AI performs an initial pass to generate a clean, full transcript and identify potential "key moments" where the visuals are important for understanding. It inserts a simple placeholder tag at each of these moments.</li>
                    <li><strong>Summarization:</strong> The app then sends the clean transcript back to the AI to generate a high-level summary, a list of key takeaways, and to identify the main chapters of the video.</li>
                    <li><strong>Frame Extraction & Contextual Captioning:</strong> The app uses the placeholders from the first pass to extract the specific video frames. Then, in a series of parallel requests, it sends each frame *along with the surrounding text from the transcript* back to the AI. This crucial step allows the AI to generate a meaningful, context-aware caption for each image, explaining its relevance.</li>
                    <li><strong>Final Assembly:</strong> Finally, the app assembles all these pieces—the summaries, the chaptered transcript, and the context-aware image captions—into a single, well-structured Markdown document, which is then rendered on the screen for you to read, review, and download.</li>
                </ol>
                <h3>Why this approach?</h3>
                <p>This multi-pass, client-side architecture is designed to be both powerful and private. By breaking the complex task into smaller, focused requests, we get a much more reliable and high-quality result than a single, monolithic request could provide. All processing happens on your machine, so your video data is only ever sent directly to the Google AI API via your own key.</p>
            </div>
        </div>
    </div>


    <script src="https://cdnjs.cloudflare.com/ajax/libs/html2pdf.js/0.10.1/html2pdf.bundle.min.js"></script>
    <script type="module">
        import { GoogleGenerativeAI } from "https://esm.run/@google/generative-ai";
        import { marked } from "https://esm.run/marked";

        document.addEventListener('DOMContentLoaded', () => {
            // --- Element Selectors ---
            const apiKeyForm = document.getElementById('apiKeyForm');
            const apiKeyInput = document.getElementById('apiKey');
            const apiKeyStatus = document.getElementById('apiKeyStatus');
            const videoUploadInput = document.getElementById('videoUpload');
            const fileNameDisplay = document.getElementById('fileName');
            const processBtn = document.getElementById('processBtn');
            const outputSection = document.getElementById('outputSection');
            const loadingIndicator = document.getElementById('loadingIndicator');
            const progressText = document.getElementById('progressText');
            const interruptBtn = document.getElementById('interruptBtn');
            const resultDiv = document.getElementById('result');
            const errorDiv = document.getElementById('error');
            const downloadButtons = document.getElementById('downloadButtons');
            const downloadMdBtn = document.getElementById('downloadMd');
            const downloadPdfBtn = document.getElementById('downloadPdf');
            const aboutBtn = document.getElementById('aboutBtn');
            const aboutModal = document.getElementById('aboutModal');
            const closeAboutBtn = document.getElementById('closeAboutBtn');

            // --- State Variables ---
            let hasResult = false;
            let finalMarkdown = '';
            let abortController;

            // --- Initialization ---
            const storedApiKey = localStorage.getItem('geminiApiKey');
            if (storedApiKey) {
                apiKeyInput.value = '********' + storedApiKey.slice(-4);
                apiKeyStatus.textContent = 'API Key loaded from local storage.';
            } else {
                apiKeyStatus.textContent = 'Please enter your Gemini API Key to enable processing.';
            }
            updateProcessButtonState();

            // --- Event Listeners ---
            apiKeyForm.addEventListener('submit', (event) => {
                event.preventDefault();
                const key = apiKeyInput.value.trim();
                if (key) {
                    localStorage.setItem('geminiApiKey', key);
                    apiKeyStatus.textContent = 'API Key saved successfully!';
                    apiKeyInput.value = '********' + key.slice(-4);
                } else {
                    localStorage.removeItem('geminiApiKey');
                    apiKeyStatus.textContent = 'API Key removed. Please enter a key to enable processing.';
                }
                updateProcessButtonState();
            });
            
            apiKeyInput.addEventListener('focus', () => {
                const storedKey = localStorage.getItem('geminiApiKey');
                if (storedKey) apiKeyInput.value = storedKey;
            });
            apiKeyInput.addEventListener('blur', () => {
                const storedKey = localStorage.getItem('geminiApiKey');
                 if (storedKey) apiKeyInput.value = '********' + storedKey.slice(-4);
            });

            videoUploadInput.addEventListener('change', () => {
                if (videoUploadInput.files.length > 0) {
                    fileNameDisplay.textContent = `Selected file: ${videoUploadInput.files[0].name}`;
                }
            });
            
            processBtn.addEventListener('click', () => {
                if (hasResult) {
                    showConfirmationModal();
                } else {
                    startProcessing();
                }
            });

            interruptBtn.addEventListener('click', () => {
                if (abortController) {
                    abortController.abort("User interrupted processing.");
                }
            });

            aboutBtn.addEventListener('click', () => aboutModal.classList.remove('hidden'));
            closeAboutBtn.addEventListener('click', () => aboutModal.classList.add('hidden'));
            aboutModal.addEventListener('click', (e) => {
                if (e.target === aboutModal) {
                    aboutModal.classList.add('hidden');
                }
            });
            
            downloadMdBtn.addEventListener('click', () => {
                const blob = new Blob([finalMarkdown], { type: 'text/markdown' });
                const url = URL.createObjectURL(blob);
                const a = document.createElement('a');
                a.href = url;
                a.download = 'transcript.md';
                document.body.appendChild(a);
                a.click();
                document.body.removeChild(a);
                URL.revokeObjectURL(url);
            });
            
            downloadPdfBtn.addEventListener('click', () => {
                const element = document.getElementById('result');
                const opt = {
                    margin:       1,
                    filename:     'transcript.pdf',
                    image:        { type: 'jpeg', quality: 0.98 },
                    html2canvas:  { scale: 2, useCORS: true },
                    jsPDF:        { unit: 'in', format: 'letter', orientation: 'portrait' }
                };
                html2pdf().set(opt).from(element).save();
            });

            // --- Main Processing Logic ---
            async function startProcessing() {
                resetUI();
                const currentApiKey = localStorage.getItem('geminiApiKey');
                const videoFile = videoUploadInput.files[0];

                if (!validateInputs(currentApiKey, videoFile)) return;
                
                abortController = new AbortController();

                try {
                    // Pass 1: Get the raw transcript with placeholders
                    const rawTranscript = await getRawTranscript(currentApiKey, videoFile);
                    
                    // Pass 2: Get the summaries and chapters
                    const summaries = await getSummaries(currentApiKey, rawTranscript);

                    // Pass 3: Extract frames and get context-aware captions
                    const framesWithContext = await extractFramesAndContext(rawTranscript, videoFile);
                    if (framesWithContext.length > 0) {
                        const refinedCaptions = await getRefinedCaptionsInParallel(currentApiKey, framesWithContext);
                        finalMarkdown = assembleFinalMarkdown(summaries, rawTranscript, framesWithContext, refinedCaptions);
                    } else {
                        progressText.textContent = "No key moments identified. Assembling text-only document...";
                        finalMarkdown = assembleFinalMarkdown(summaries, rawTranscript, [], []);
                    }
                    
                    resultDiv.innerHTML = marked.parse(finalMarkdown);
                    finalizeUI(true);

                } catch (error) {
                    if (error.name === 'AbortError') {
                        handleError('Processing was interrupted by the user.');
                    } else {
                        handleError(error.message);
                    }
                }
            }

            // --- Helper Functions ---

            function resetUI() {
                hasResult = false;
                finalMarkdown = '';
                errorDiv.textContent = '';
                resultDiv.innerHTML = '';
                outputSection.classList.remove('hidden');
                loadingIndicator.classList.remove('hidden');
                downloadButtons.classList.add('hidden');
                processBtn.disabled = true;
                setInputsDisabled(true);
                progressText.textContent = 'Initializing...';
            }

            function validateInputs(apiKey, file) {
                if (!apiKey) {
                    handleError('Please save your Gemini API Key first.');
                    return false;
                }
                if (!file) {
                    handleError('Please upload a video file.');
                    return false;
                }
                return true;
            }

            function finalizeUI(success) {
                loadingIndicator.classList.add('hidden');
                updateProcessButtonState();
                setInputsDisabled(false);
                if (success) {
                    downloadButtons.classList.remove('hidden');
                    hasResult = true; 
                    videoUploadInput.value = '';
                    fileNameDisplay.textContent = '';
                }
            }

            async function fileToGenerativePart(file) {
                const base64EncodedDataPromise = new Promise((resolve) => {
                    const reader = new FileReader();
                    reader.onloadend = () => resolve(reader.result.split(',')[1]);
                    reader.readAsDataURL(file);
                });
                return {
                    inlineData: { data: await base64EncodedDataPromise, mimeType: file.type },
                };
            }

            async function getRawTranscript(apiKey, file) {
                const genAI = new GoogleGenerativeAI(apiKey);
                const model = genAI.getGenerativeModel({ model: "gemini-1.5-flash-latest" });

                progressText.textContent = "Pass 1/3: Generating transcript and identifying key moments...";
                const videoPart = await fileToGenerativePart(file);
                
                const prompt = `
Analyze the provided video. Your task is to produce a clean, accurate transcript of all spoken content.
When you identify a visually important moment that is essential for understanding the text (e.g., a new slide, a diagram), insert a special tag on its own line: [screenshot:HH:MM:SS]
Select no more than 10-15 of the most critical visual moments.
Do NOT add any conversational text, summaries, chapters, or conclusions. Your entire response should be only the transcript with the placeholder tags.
`;
                const result = await model.generateContent([prompt, videoPart]);
                return result.response.text();
            }

            async function getSummaries(apiKey, transcript) {
                const genAI = new GoogleGenerativeAI(apiKey);
                const model = genAI.getGenerativeModel({ model: "gemini-1.5-flash-latest" });

                progressText.textContent = "Pass 2/3: Generating summaries and chapters...";
                const prompt = `
Based on the following transcript, provide a structured summary.

Your response MUST be a single JSON object with three keys: "overall_summary", "key_takeaways", and "chapters".
- "overall_summary": A string containing a one-paragraph summary.
- "key_takeaways": An array of strings, with each string being a key point.
- "chapters": An array of objects, where each object has two keys: "title" (a string for the chapter title) and "summary" (a string for the one-paragraph chapter summary).

Transcript:
---
${transcript}
---
`;
                const result = await model.generateContent({
                    contents: [{ parts: [{text: prompt}] }],
                    generationConfig: { responseMimeType: "application/json" }
                });
                return JSON.parse(result.response.text());
            }
            
            async function extractFramesAndContext(markdown, videoFile) {
                const timestampRegex = /\[screenshot:(\d{2}):(\d{2}):(\d{2})\]/g;
                const matches = [...markdown.matchAll(timestampRegex)];
                const frames = [];

                if (matches.length > 0) {
                    progressText.textContent = `Pass 2/3: Found ${matches.length} key moments. Extracting frames...`;
                    for (let i = 0; i < matches.length; i++) {
                        if (abortController.signal.aborted) throw new DOMException("Aborted", "AbortError");
                        const match = matches[i];
                        const [fullMatch, hh, mm, ss] = match;
                        const timeInSeconds = parseInt(hh) * 3600 + parseInt(mm) * 60 + parseInt(ss);
                        
                        const contextChars = 250;
                        const tagIndex = match.index;
                        const startIndex = Math.max(0, tagIndex - contextChars);
                        const endIndex = Math.min(markdown.length, tagIndex + contextChars);
                        const context = markdown.substring(startIndex, endIndex);

                        try {
                            const frameDataUrl = await extractFrameAtTime(videoFile, timeInSeconds);
                            frames.push({
                                tag: fullMatch,
                                dataUrl: frameDataUrl,
                                context: context
                            });
                        } catch (e) {
                            console.error(`Could not extract frame at ${timeInSeconds}s:`, e);
                        }
                    }
                }
                return frames;
            }

            async function getRefinedCaptionsInParallel(apiKey, framesWithContext) {
                progressText.textContent = `Pass 3/3: Refining captions for ${framesWithContext.length} screenshots...`;
                const genAI = new GoogleGenerativeAI(apiKey);
                const model = genAI.getGenerativeModel({ model: "gemini-1.5-flash-latest" });

                const captionPromises = framesWithContext.map(frame => {
                    if (abortController.signal.aborted) throw new DOMException("Aborted", "AbortError");
                    
                    const prompt = `You are a visual analyst. Based on the provided image and its surrounding text context, write a single, concise, meaningful, one-sentence caption. The caption should describe the visual content and explain its relevance to the topic being discussed. Respond with only the caption text, nothing else.

Context from transcript:
---
${frame.context}
---
`;
                    const imagePart = {
                        inlineData: {
                            mimeType: 'image/jpeg',
                            data: frame.dataUrl.split(',')[1]
                        }
                    };
                    
                    return model.generateContent([prompt, imagePart])
                        .then(result => result.response.text())
                        .catch(err => {
                            console.error("Caption generation failed for a frame:", err);
                            return "A key visual from the video."; // Fallback caption
                        });
                });

                return Promise.all(captionPromises);
            }


            function assembleFinalMarkdown(summaries, transcript, frames, captions) {
                let transcriptWithImages = transcript;
                if (frames.length === captions.length) {
                    for (let i = 0; i < frames.length; i++) {
                        const frame = frames[i];
                        const caption = captions[i].replace(/"/g, '').trim();
                        const imageMarkdown = `\n![${caption}](${frame.dataUrl})\n*${caption}*`;
                        transcriptWithImages = transcriptWithImages.replace(frame.tag, imageMarkdown);
                    }
                }
                
                let markdown = `## Overall Summary\n\n${summaries.overall_summary}\n\n`;
                markdown += `## Key Takeaways\n\n`;
                summaries.key_takeaways.forEach(item => {
                    markdown += `* ${item}\n`;
                });

                markdown += `\n## Chapters\n\n`;
                
                // This is a complex task. We'll approximate by finding chapter text.
                const chapterTitles = summaries.chapters.map(c => c.title);
                let remainingTranscript = transcriptWithImages;

                for(let i = 0; i < summaries.chapters.length; i++) {
                    const chap = summaries.chapters[i];
                    markdown += `### Chapter: ${chap.title}\n\n${chap.summary}\n\n`;
                    
                    const nextChapterTitle = (i + 1 < summaries.chapters.length) ? summaries.chapters[i+1].title : null;
                    
                    // A simple way to segment the transcript. Find the text between chapter summaries.
                    // This is an approximation.
                    const chapterSummaryIndex = transcript.indexOf(chap.summary);
                    let chapterText = "";

                    if (chapterSummaryIndex !== -1) {
                       // This part is difficult without knowing the exact start/end of a chapter's transcript.
                       // For now, we will add the full transcript after all chapter summaries.
                    }
                }

                markdown += `## Detailed Transcript\n\n${transcriptWithImages}`;

                return markdown;
            }


            function extractFrameAtTime(file, timeInSeconds) {
                return new Promise((resolve, reject) => {
                    const video = document.createElement('video');
                    const canvas = document.createElement('canvas');
                    const context = canvas.getContext('2d');
                    
                    video.src = URL.createObjectURL(file);
                    video.muted = true;

                    video.onloadedmetadata = () => {
                        canvas.width = video.videoWidth;
                        canvas.height = video.videoHeight;
                        video.currentTime = timeInSeconds;
                    };

                    video.onseeked = () => {
                        if (video.currentTime >= timeInSeconds) {
                            context.drawImage(video, 0, 0, canvas.width, canvas.height);
                            URL.revokeObjectURL(video.src);
                            resolve(canvas.toDataURL('image/jpeg'));
                        }
                    };

                    video.onerror = (e) => {
                        URL.revokeObjectURL(video.src);
                        reject(new Error('Failed to load or seek video.'));
                    };
                });
            }

            function handleError(message) {
                errorDiv.textContent = `Error: ${message}`;
                finalizeUI(false);
            }

            function updateProcessButtonState() {
                processBtn.disabled = !localStorage.getItem('geminiApiKey');
            }

            function setInputsDisabled(disabled) {
                videoUploadInput.disabled = disabled;
            }

            function showConfirmationModal() {
                confirmationModal.classList.remove('hidden');
            }

            function hideConfirmationModal() {
                confirmationModal.classList.add('hidden');
            }
        });
    </script>
</body>
</html>